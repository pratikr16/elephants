[
["index.html", "Fine-Scale Tracking of Ambient Temperature and Movement Reveals Shuttling Behavior of Elephants to Water Section 1 About 1.1 Contact 1.2 Data access 1.3 Data processing", " Fine-Scale Tracking of Ambient Temperature and Movement Reveals Shuttling Behavior of Elephants to Water Maria Thaker, Pratik R. Gupte, Herbert HT Prins, Rob Slotow, and Abi T. Vanak January 2019 Section 1 About This is the source code for the publication Thaker M, Gupte PR, Prins HHT, et al (2019) Fine-Scale Tracking of Ambient Temperature and Movement Reveals Shuttling Behavior of Elephants to Water. Front Ecol Evol 7:. doi: 10.3389/fevo.2019.00004 1.1 Contact Corresponding author Dr. Maria Thaker Centre for Ecological Sciences, Indian Institute of Science. Email: m.thaker@iisc.ac.in Code maintainer Pratik R. Gupte Groningen Institute for Evolutionary Life Sciences, University of Groningen. Email: p.r.gupte@rug.nl 1.2 Data access The tracking dataset collected for use in this work is available from Movebank: https://doi.org/10.5441/001/1.403h24q5 Other data used in this study are cited in the text. 1.3 Data processing The data processing for this project is described in the following sections. Navigate through them using the links in the sidebar. "],
["collar-temperature-and-ambient-temperature.html", "Section 2 Collar temperature and ambient temperature 2.1 Load libraries 2.2 Load tracking and temperature data 2.3 Select ele data near tower 2.4 Combine collar and ambient temp 2.5 Exploring collar and ambient temp 2.6 Model collar and ambient temp 2.7 Global Bland-Altman test 2.8 Figure 3: Collar and ambient temperature", " Section 2 Collar temperature and ambient temperature Here we model the relationship between the temperature reported by inbuilt temperature sensors on the elephants’ GPS collars, and the ambient temperature recorded at Skukuza. For this comparison, we will only use data from positions recorded within 10 km of the weathe weather tower at Skukuza. 2.1 Load libraries # load libraries library(dplyr) library(purrr) library(lubridate) library(readr) library(readxl) library(glue) library(stringr) library(forcats) # spatial library(sf) # plotting library(ggplot2) library(ggthemes) library(viridis) # custom funcs ci = function(x) 1.96*sd(x, na.rm = T)/sqrt(length(x)) 2.2 Load tracking and temperature data Read the tracking data from a number of elephants from 2006 – 2011. Read in the ambient temperature for approximately the same range, 2007 – 2010. Handle the date and time columns correctly using lubridate and floor the time to the nearest half hour. # read in data saved as csv from an excel file data = read_csv(&quot;data/AllEles2011_UTM.csv&quot;) # read in temperature data and select relevant cols amb_temp = read_csv(&quot;data/skukuza_tower_temp.csv&quot;) %&gt;% `colnames&lt;-`(c(&quot;date&quot;,&quot;time&quot;,&quot;prop_time&quot;,&quot;col4&quot;,&quot;temp.a&quot;,&quot;col6&quot;,&quot;col7&quot;)) %&gt;% select(date, prop_time, temp.a) %&gt;% mutate(date = fast_strptime(date, format = &quot;%d/%m/%Y&quot;, lt = F), time = as.numeric(date) + prop_time*24*3600, time = as.POSIXct(time, origin = &quot;1970-01-01&quot;), time = floor_date(time, unit = &quot;30 minutes&quot;)) %&gt;% select(time, temp.a) # read in tower location skukuza = read_csv(&quot;data/skukuza.csv&quot;) %&gt;% st_as_sf(coords = c(&quot;long&quot;,&quot;lat&quot;), crs = 4326) %&gt;% st_transform(st_crs(32736)) # get buffer around skukuza skz_buf = st_buffer(skukuza, dist = 10000) 2.3 Select ele data near tower 2.3.1 Convert to sf and filter # make ele data spatial data_sf = st_as_sf(data, coords = c(&quot;XUTM&quot;,&quot;YUTM&quot;)) st_crs(data_sf) = 32736 # which eles are inside the buffer data_keep = st_contains(skz_buf, data_sf) data_keep = unlist(data_keep) # eles to keep data_tower = data[data_keep,] 2.3.2 Clean filtered data Here, process the date and time by converting the Date_Time column to POSIXct. Then convert time to POSIXct by adding the proportional daily time to the numeric date. Finally, round the time to the nearest half hour. As a sanity check, do the increments of Time_Number follow the increments in time? #&#39;clean ele data data.tow.clean = data_tower %&gt;% mutate(date = fast_strptime(Date_Time, format = &quot;%d/%m/%Y&quot;, lt = F), time = as.POSIXct(as.numeric(date) + TimeNumber*24*60*60, origin = &quot;1970-01-01&quot;), time = floor_date(time, &quot;30 min&quot;)) %&gt;% rename(temp = TempC) 2.4 Combine collar and ambient temp 2.4.1 Prepare data for Bland-Altman Join the elephant data within 10 km of the tower with ambient temperature data from the tower by the time column. Exploring the data reveals that ambient temperature data records NA as -9999. Filter the data to exclude these values. #&#39;match ele and flux tower data.tow.clean.ba = data.tow.clean %&gt;% select(id = UnitID, time, temp, season = Season) %&gt;% left_join(amb_temp) # filter combined data data.tow.clean.ba = data.tow.clean.ba %&gt;% filter(temp.a &gt;= -5, !is.na(temp), !is.na(temp.a)) %&gt;% mutate(hour = hour(time), season = as_factor(season), temp = as.numeric(temp)) 2.4.2 Prepare Fig. 3 (A): Daily temperature trend # make figure of temps per hour of day data_fig3a = data.tow.clean.ba %&gt;% group_by(hour, season) %&gt;% summarise_at(vars(temp, temp.a), list(mean = mean, ci = ci)) fig_temp_measure_hour = ggplot(data_fig3a, aes(x = hour))+ geom_rangeframe(data = data_frame(x = c(0,23), y=c(15,40)), aes(x,y))+ geom_path(aes(y = temp_mean, col = season), lty = 1)+ geom_path(aes(y = temp.a_mean, col = season), lty=2)+ geom_ribbon(aes(ymin = temp_mean - temp_ci, ymax = temp_mean + temp_ci, group = season, fill = season), alpha = 0.2)+ geom_ribbon(aes(ymin = temp.a_mean - temp.a_ci, ymax = temp.a_mean + temp.a_ci, group = season, fill = season), alpha = 0.2)+ scale_colour_brewer(palette = &quot;Set1&quot;)+ scale_fill_brewer(palette = &quot;Set1&quot;)+ scale_x_continuous(breaks = c(0,4,8,12,16,20,23))+ scale_y_continuous(breaks = seq(15,40,5))+ theme_few()+ theme(legend.position = &quot;none&quot;, panel.border = element_blank(), axis.text = element_text(size = 8), axis.title = element_text(size = 8))+ coord_cartesian(xlim = c(0,23))+ labs(x = &quot;Hour of day&quot;, y = &quot;Temperature (°C)&quot;, title = &quot;(a)&quot;) 2.5 Exploring collar and ambient temp 2.5.1 Prepare data for models # load statistical package lme4 library(lme4) mean_wo_na = function(x) mean(x, na.rm=T) sd_wo_na = function(x) sd(x, na.rm = T) # random effects model for within individual and hour std deviation # get the mean data ele.BA.data = ungroup(data.tow.clean.ba) %&gt;% mutate(diff = temp-temp.a, mean.temp = (temp+temp.a)/2) %&gt;% mutate(hour.plot = paste(str_pad(hour, 2, side = &quot;left&quot;, pad = &quot;0&quot;), &quot;:00&quot;, sep = &quot;&quot;)) 2.5.2 Run models per hour # run mods in each hour ele.BA.mods = ungroup(ele.BA.data) %&gt;% split(ele.BA.data$hour.plot) %&gt;% map(function(x){ lmer(temp ~ temp.a + season + (1|id), data = x) }) # prepare predict data ele.pred.data = ele.BA.data %&gt;% split(ele.BA.data$hour.plot) # predict from the model on prepared data ele.tempmod.fit = map2(ele.pred.data, ele.BA.mods, function(x,y){ x %&gt;% mutate(pred = predict(y, newdata = x, type = &quot;response&quot;, se.fit = T)) }) %&gt;% bind_rows() 2.5.3 Prepare data for plotting Extract the variance-correlation components from the hour-wise models using lme4::VarCorr. Get the standard deviation for each hour. # summarise model data using multiple maps ele.ba.summary = ele.BA.mods %&gt;% map(.f = VarCorr) %&gt;% map(function(x){ data_frame(sd_id = as.data.frame(x) %&gt;% .$sdcor %&gt;% sum()) }) %&gt;% bind_rows() %&gt;% mutate(hour = 0:23) %&gt;% mutate(hour.plot = paste(str_pad(hour, 2, side = &quot;left&quot;, pad = &quot;0&quot;), &quot;:00&quot;, sep = &quot;&quot;)) # get the mean differences from the data prepared for the model # join to the hour-wise standard deviation mean_diff = ele.BA.data %&gt;% group_by(hour.plot) %&gt;% summarise(diff = mean(diff, na.rm = T)) %&gt;% left_join(ele.ba.summary) 2.5.4 Prepare Bland-Altman plots Plot the hour-wise relationship between collar temperature and ambient temperature, and the hour-wise Bland-Altman plots. #&#39;make appendix figure a fig_temp_rel_hr = ggplot()+ geom_rangeframe(data = data_frame(x=c(10,40), y = c(0,40)), aes(x,y))+ geom_point(data = ele.BA.data, aes(x = temp.a, y = temp), size = 0.1, alpha = 0.2)+ geom_smooth(data = ele.tempmod.fit, aes(x = temp.a, y = pred), method = &quot;glm&quot;, col = &quot;steelblue&quot;)+ geom_abline(slope = 1, lty = 2, col = 1, lwd = 0.2)+ scale_x_continuous(breaks = c(10,25,40))+ facet_wrap(~hour.plot, nrow = 4)+ theme_few()+ coord_fixed()+ theme(panel.border = element_blank())+ labs(x = &quot;Ambient temperature (°C)&quot;, y = &quot;Collar temperature (°C)&quot;, title = &quot;(a)&quot;) #&#39;appendix figure b fig_ba_hour = ggplot()+ geom_rangeframe(data = data_frame(x=c(10,40), y = c(-10,30)), aes(x,y))+ geom_point(data = ele.BA.data, aes(x = mean.temp, y = diff), size = 0.1, alpha = 0.2)+ geom_abline(slope = 0, lty = 2, col = 1, lwd = 0.2)+ geom_hline(data = mean_diff, aes(yintercept = diff), col = &quot;brown&quot;)+ geom_hline(data = mean_diff, aes(yintercept = 1.96*sd_id + diff), col = &quot;steelblue&quot;)+ geom_hline(data = mean_diff, aes(yintercept = diff - 1.96*sd_id), col = &quot;steelblue&quot;)+ #coord_cartesian(ylim = c(0,40), xlim = c(0,40))+ scale_y_continuous(breaks = seq(-10,30, 10))+ scale_x_continuous(breaks = c(10,25,40))+ theme_few()+ theme(panel.background = element_blank())+ facet_wrap(~hour.plot, nrow = 4)+ coord_fixed()+ theme(panel.border = element_blank())+ labs(x = &quot;Mean (amb &amp; collar) temp. (°C)&quot;, y = &quot;Collar - amb. temp. (°C)&quot;, title = &quot;(b)&quot;) fig_hourwise_collar_ambient = gridExtra::grid.arrange(fig_temp_rel_hr, fig_ba_hour, nrow = 1) ggsave(fig_hourwise_collar_ambient, filename = &quot;figs/fig_hourwise_collar_ambient.png&quot;, device = png(), height = 180/25.4, width = 1.5*180*1.2/25.4, dpi = 300) 2.6 Model collar and ambient temp 2.6.1 LMM collar and ambient temp Run a global linear mixed effects model for collar temperature as a function of ambient temperature. Write the model summary to a text file. # run global lmm for collar and ambient temperature mod.temp = lmer(temp ~ temp.a + season + (1|hour) + (1|id), data = data.tow.clean.ba) # write model summary if(!dir.exists(&quot;data/model_output&quot;)){ dir.create(&quot;data/model_output&quot;) } # clear old output if(file.exists(&quot;data/model_output/model_collar_amb_temp.txt&quot;)){ file.remove(&quot;data/model_output/model_collar_amb_temp.txt&quot;) } R.utils::captureOutput(summary(mod.temp), file = &quot;data/model_output/model_collar_amb_temp.txt&quot;, append = TRUE) R.utils::captureOutput(car::Anova(mod.temp), file = &quot;data/model_output/model_collar_amb_temp.txt&quot;, append = TRUE) Print the model summary. cat(readLines(&quot;data/model_output/model_collar_amb_temp.txt&quot;), sep = &quot;\\n&quot;) Linear mixed model fit by REML [&#39;lmerMod&#39;] Formula: temp ~ temp.a + season + (1 | hour) + (1 | id) Data: data.tow.clean.ba REML criterion at convergence: 77689.3 Scaled residuals: Min 1Q Median 3Q Max -4.2505 -0.6336 0.0434 0.6518 5.0781 Random effects: Groups Name Variance Std.Dev. hour (Intercept) 12.825 3.581 id (Intercept) 3.865 1.966 Residual 7.473 2.734 Number of obs: 15982, groups: hour, 24; id, 4 Fixed effects: Estimate Std. Error t value (Intercept) 13.566910 1.254904 10.81 temp.a 0.610849 0.006104 100.07 seasonDry -1.073253 0.051963 -20.65 Correlation of Fixed Effects: (Intr) temp.a temp.a -0.117 seasonDry -0.067 0.365 Analysis of Deviance Table (Type II Wald chisquare tests) Response: temp Chisq Df Pr(&gt;Chisq) temp.a 10014.04 1 &lt; 2.2e-16 *** season 426.59 1 &lt; 2.2e-16 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 2.6.2 Get variance components # calculate variance components and print # variance of random effects var_eff_hour = as.numeric(VarCorr(mod.temp))[1] var_eff_Id = as.numeric(VarCorr(mod.temp))[2] # residual var_res = as.numeric(attr(VarCorr(mod.temp), &quot;sc&quot;)^2) # fixed effects only var_fix = var(predict(lm(temp ~ temp.a + season, data = data.tow.clean.ba))) # total data variance var_tot = var(data.tow.clean.ba$temp) # proportional variances p_var = c(var_eff_hour, var_eff_Id, var_res, var_fix)*100/var_tot # make data frame and save mod_collar_amb_temp_variance = data_frame(component = c(&quot;hour&quot;, &quot;id&quot;, &quot;residual&quot;, &quot;fixed_effects&quot;), variance = c(var_eff_hour, var_eff_Id, var_res, var_fix), percentage = p_var) # write to file write_csv(mod_collar_amb_temp_variance, path = &quot;data/model_output/mod_collar_amb_temp_variance.txt&quot;) Print the variance components of the model. variance_comp_temp_amb = read_csv(&quot;data/model_output/mod_collar_amb_temp_variance.txt&quot;) knitr::kable(variance_comp_temp_amb) component variance percentage hour 12.824898 27.160790 id 3.865104 8.185584 residual 7.472789 15.826000 fixed_effects 31.916336 67.592966 2.6.3 Prepare Figure 3 (B): Collar ~ ambient temperature Prepare a figure of the relationship between collar temperature and ambient temperature. This forms figure 3B of the manuscript. # plot figure of mean relationship collar and ambient temp fig_temp_rel_data &lt;- data.tow.clean.ba %&gt;% group_by(season, temp.a = round(temp.a)) %&gt;% summarise_at(vars(temp), list(temp_mean = mean, temp_ci = ci)) fig_temp_measure_relation &lt;- ggplot()+ geom_smooth(data = fig_temp_rel_data, aes(x = temp.a, y = temp_mean, group = season, col = season, fill = season), method = &quot;glm&quot;, se =T, alpha = 0.2,lwd = 0.5)+ geom_pointrange(data = fig_temp_rel_data, aes(x = temp.a, y = temp_mean, ymin = temp_mean-temp_ci , ymax = temp_mean+temp_ci, shape = season, col = season), position = position_dodge(width = 0.5), fill = &quot;white&quot;, size = 0.1, stroke = 0.4)+ geom_rangeframe(data = data_frame(x = c(5,40), y = c(4,44)), aes(x,y))+ geom_abline(slope = 1, lty = 2)+ scale_colour_brewer(palette = &quot;Set1&quot;)+ scale_fill_brewer(palette = &quot;Set1&quot;)+ scale_shape_manual(values = c(21, 24))+ scale_x_continuous(breaks = seq(5,40,5))+ scale_y_continuous(breaks = seq(4,44,8))+ coord_cartesian(xlim=c(5,40), ylim = c(5,44))+ theme_few()+ theme(panel.border = element_blank(), legend.position = &quot;none&quot;, axis.text = element_text(size = 8), axis.title = element_text(size = 8))+ labs(x = &quot;Ambient temperature (°C)&quot;, y = &quot;Collar temperature (°C)&quot;, title = &quot;(b)&quot;) 2.7 Global Bland-Altman test Prepare a global Bland Altman test and associated plots. 2.7.1 Prepare data for global Bland-Altman # get data for global BA plot ele.BA.data = ele.BA.data %&gt;% filter(!is.na(temp), !is.na(temp.a)) %&gt;% ungroup() %&gt;% group_by(id, hour, season) %&gt;% summarise_at(vars(temp, temp.a), funs(mean)) %&gt;% mutate(mean.measures = (temp+temp.a)/2, diff.measures = temp-temp.a) %&gt;% ungroup() %&gt;% group_by(mean.measures = round(mean.measures), season) %&gt;% summarise_at(vars(diff.measures), funs(mean)) 2.7.2 GAMM for Bland-Altman trend # run a gamm of differences vs mean for the BA data library(mgcv) BA.gam = gam(diff.measures ~ s(mean.measures, by = season), data = ele.BA.data) # write summary to file and then read and show # clear old output if(file.exists(&quot;data/model_output/model_gamm_BA.txt&quot;)){ file.remove(&quot;data/model_output/model_gamm_BA.txt&quot;) } R.utils::captureOutput(summary(BA.gam), file = &quot;data/model_output/model_gamm_BA.txt&quot;, append = TRUE) # get model predictions ele.BA.data$pred = predict(BA.gam, type = &quot;response&quot;, newdata = ele.BA.data, se.fit = T)[[1]] ele.BA.data$se = predict(BA.gam, type = &quot;response&quot;, newdata = ele.BA.data, se.fit = T)[[2]] Print the GAMM summary. cat(readLines(&quot;data/model_output/model_gamm_BA.txt&quot;), sep = &quot;\\n&quot;) Family: gaussian Link function: identity Formula: diff.measures ~ s(mean.measures, by = season) Parametric coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 4.5342 0.2535 17.89 3.82e-15 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Approximate significance of smooth terms: edf Ref.df F p-value s(mean.measures):seasonWet 1.593 1.980 11.36 0.00025 *** s(mean.measures):seasonDry 2.012 2.509 16.46 7.09e-06 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 R-sq.(adj) = 0.704 Deviance explained = 74.4% GCV = 2.0248 Scale est. = 1.6918 n = 28 2.7.3 Prepare Fig. 3 (C): Bland-Altman plot # prepare global bland altman figure figBArevised = ggplot(ele.BA.data)+ geom_ribbon(aes(x = mean.measures, ymin = pred-se, ymax = pred+se, fill = season), alpha = 0.2)+ geom_line(aes(x = mean.measures, y = pred, col = season), lty = 2)+ geom_point(aes(x = mean.measures, y = diff.measures, col = season, shape = season), fill = &quot;white&quot;, size = 1,stroke = 0.5)+ scale_color_brewer(palette = &quot;Set1&quot;, direction = -1)+ scale_fill_brewer(palette = &quot;Set1&quot;)+ scale_shape_manual(values = c(24,21))+ geom_rangeframe(data = data_frame(x=c(15,35), y = c(-5,20)), aes(x,y))+ geom_hline(yintercept = c(0,mean(mean_diff$diff), mean(mean_diff$diff) + 1.96*mean(mean_diff$sd_id), mean(mean_diff$diff) - 1.96*mean(mean_diff$sd_id)), lty = c(2,1,1,1), lwd = c(0.2, 0.4,0.4,0.4), col = c(&quot;black&quot;,&quot;brown&quot;,&quot;steelblue&quot;,&quot;steelblue&quot;))+ theme_few()+ theme(legend.position = &quot;none&quot;, panel.border = element_blank(), axis.text = element_text(size = 8), axis.title = element_text(size = 8))+ scale_y_continuous(breaks = c(seq(-5,20, 5)))+ labs(x = &quot;Mean (collar &amp; amb.) temp (°C)&quot;, y = &quot;Collar temp. - amb. temp. (°C)&quot;, title = &quot;(c)&quot;) 2.7.4 Write hourly model summaries to file Gather model output for temperature models per hour and write to file. # hourly model output # this is complicated code, please don&#39;t do it this way ele.temp.mods.summary = ele.BA.mods %&gt;% map(summary) %&gt;% map(function(x){ x$coefficients %&gt;% as.data.frame() %&gt;% select(Estimate, `t value`) %&gt;% mutate(predictor = rownames(.)) %&gt;% tidyr::gather(lmm_output, value, -predictor) %&gt;% filter(predictor != (&quot;(Intercept)&quot;)) %&gt;% mutate(value = plyr::round_any(value, 0.01)) %&gt;% tidyr::spread(lmm_output, value)}) %&gt;% bind_rows() %&gt;% mutate(hour = rep(0:23, each = 2), predictor = ifelse(predictor != &quot;temp.a&quot;, &quot;season&quot;, predictor)) %&gt;% left_join(map(ele.BA.mods, function(x){ car::Anova(x) %&gt;% as.data.frame() %&gt;% mutate(predictor = rownames(.)) %&gt;% rename(p_value = `Pr(&gt;Chisq)`) %&gt;% select(-Df)}) %&gt;% bind_rows() %&gt;% mutate(hour = rep(0:23, each = 2), Chisq = plyr::round_any(Chisq, 0.1), p_value = plyr::round_any(p_value, 0.001))) # export to csv write_csv(ele.temp.mods.summary, path = &quot;data/model_output//ele_temp_mods_summary.txt&quot;) 2.8 Figure 3: Collar and ambient temperature half = 85/25.4; full = 180/25.4 # export fig for temp measures library(gridExtra) figure_03_temperature_sources = grid.arrange(fig_temp_measure_hour, fig_temp_measure_relation, figBArevised, nrow = 1) ggsave(figure_03_temperature_sources, filename = &quot;figs/figure_03_temperature_sources.pdf&quot;, height = half, width = full) library(magick) fig03 = magick::image_read_pdf(&quot;figs/figure_03_temperature_sources.pdf&quot;) fig03 (#fig:show_figure_03)(a) Mean collar temperature (solid lines) and measured ambient temperature from Skukuza flux tower (dashed lines) at each hour of day in each season (dry: red lines, wet: blue lines) over the study period. Ninety-Five percent confidence intervals (CI) about each line are shaded. (b) Correlation between mean collar temperature from elephants within 10 km of the Skukuza flux tower (from n = 3 elephants) and time-matched ambient temperatures measured by the flux tower in each season (dry: red circles, wet: blue triangles). The dashed line denotes the line of identity where collar temperature equals ambient temperature. Bars represent 95% CI at each point. (c) Bland-Altman limits of agreement plot comparing collar temperatures and ambient temperatures from the Skukuza flux tower, accounting for repeated measures of individual elephants and hour of day (n = 28,853 total comparisons). The bias between the two measures at each mean temperature is marked by symbols colored by season (dry: red circles, wet: blue triangles). The black dashed line marks zero difference between the two measures. The upper and lower limits of agreement are shown as the standard normal deviate (1.96) times the standard deviation due to elephant identity, and are marked by solid blue lines, while the mean difference in measures is marked by the solid red line. "],
["speed-and-collar-temperature.html", "Section 3 Speed and collar temperature 3.1 Load libraries 3.2 Load data from sources 3.3 Speed and temperature 3.4 Figure 4: Speed and temperature and woody cover", " Section 3 Speed and collar temperature Here we look at the relationship between elephant speed and collar temperature, as well as some other relevant factors that we think might influence elephant movement. 3.1 Load libraries # load libraries library(dplyr) library(purrr) library(lubridate) library(readr) # stats library(mgcv) # spatial library(sf) library(raster) # plotting library(ggplot2) library(ggthemes) library(viridis) # custom funcs ci = function(x) 1.96*sd(x, na.rm = T)/sqrt(length(x)) 3.2 Load data from sources Load the tracking data and the transformed slope data. # read in eles as csv data = read_csv(&quot;data/elephant_data.csv&quot;) 3.3 Speed and temperature 3.3.1 Run GAMM speed ~ temperature # make id a factor data$id = as.factor(data$id) data$season = as.factor(data$season) # run a GAMM using the mgcv package mod.speed = bam(v ~ s(temp, k = 4) + season + woody.density + s(id, bs = &quot;re&quot;) + s(hour, bs = &quot;re&quot;), data = data) # print model summary to file if(!dir.exists(&quot;data/model_output&quot;)){ dir.create(&quot;data/model_output&quot;) } if(file.exists(&quot;data/model_output/model_gamm_speed.txt&quot;)){ file.remove(&quot;data/model_output/model_gamm_speed.txt&quot;) } R.utils::captureOutput(summary(mod.speed), file = &quot;data/model_output/model_gamm_speed.txt&quot;, append = TRUE) Print the GAMM summary. cat(readLines(&quot;data/model_output/model_gamm_speed.txt&quot;), sep = &quot;\\n&quot;) Family: gaussian Link function: identity Formula: v ~ s(temp, k = 4) + season + woody.density + s(id, bs = &quot;re&quot;) + s(hour, bs = &quot;re&quot;) Parametric coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 252.55538 5.20079 48.56 &lt;2e-16 *** seasonwet 16.48085 0.86423 19.07 &lt;2e-16 *** woody.density -1.60256 0.03278 -48.89 &lt;2e-16 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Approximate significance of smooth terms: edf Ref.df F p-value s(temp) 2.995 3 4716.1 &lt;2e-16 *** s(id) 12.890 13 131.2 &lt;2e-16 *** s(hour) 0.991 1 112.6 &lt;2e-16 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 R-sq.(adj) = 0.0667 Deviance explained = 6.68% fREML = 1.9511e+06 Scale est. = 52787 n = 284572 3.3.2 Prepare speed ~ temp plot data # prepare data for plotting ele.speed.temp = data %&gt;% mutate(v.pred = predict(mod.speed, newdata = ., scale = &quot;response&quot;, allow.new.levels = T), temp = plyr::round_any(temp,2)) %&gt;% ungroup() %&gt;% group_by(season, temp) %&gt;% summarise(v.mean = mean(v), v.sd = sd(v), n.v = length(v), pred.mean = mean(v.pred, na.rm = T), pred.sd=sd(v.pred, na.rm = T), pred.n = length(v.pred)) %&gt;% mutate(v.ci = qnorm(0.975)*v.sd/sqrt(n.v), ci.pred = qnorm(0.975)*pred.sd/sqrt(pred.n)) 3.3.3 Prepare Figure 4 (A): Speed and temperature # figure for speed and temperature fig_speed_temp = ele.speed.temp %&gt;% filter(temp %in% 10:40) %&gt;% ggplot()+ geom_rangeframe(data = data_frame(x=c(10,40), y = c(0.15,0.6)),aes(x,y))+ geom_smooth(aes(x = temp, y = pred.mean*2/1e3, col = season, fill = season, lty = season), alpha = 0.2, lwd = 0.5)+ geom_pointrange(aes(x = temp, y = v.mean*2/1e3, ymin = (v.mean-v.ci)*2/1e3, ymax = (v.mean+v.ci)*2/1e3, col = season, shape = season), fill = &quot;white&quot;, size = 0.4, stroke =0.7, lty = 1, position = position_dodge(width = 0.3))+ scale_fill_brewer(palette = &quot;Set1&quot;)+ scale_color_brewer(palette = &quot;Set1&quot;)+ scale_shape_manual(values=c(21,24))+ scale_linetype_manual(values=c(&quot;dashed&quot;,&quot;solid&quot;))+ theme_few()+ theme(panel.border = element_blank(), legend.position = &quot;none&quot;)+ coord_cartesian(ylim=c(0.15,0.6))+ scale_y_continuous(breaks = seq(.15,.6,.15))+ labs(x = &quot;Collar temperature (°C)&quot;, y = &quot;Speed (km/h)&quot;, col = &quot;Season&quot;, fill = &quot;Season&quot;, title=&quot;(a)&quot;) 3.3.4 Prepare data for speed ~ woodland plot # prepare data ele.speed.wood = as_data_frame(data) %&gt;% mutate(v.pred = predict(mod.speed, newdata = ., scale = &quot;response&quot;, allow.new.levels = T)) %&gt;% dplyr::select(woody.density, v, v.pred, season) %&gt;% mutate(v2 = v*2/1e3, v.pred2 = v.pred*2/1e3) %&gt;% dplyr::select(-v, -v.pred) %&gt;% tidyr::gather(var, value, -woody.density, -season) %&gt;% group_by(season, wood = plyr::round_any(woody.density, 5),var) %&gt;% summarise_at(vars(value), list(mean=mean, sd=sd, length=length)) %&gt;% mutate(ci = 1.96*sd/sqrt(length)) 3.3.5 Prepare Figure 4 (B): Speed and woody cover #review figs: speed vs slope, speed vs woody density fig_speed_wood = ggplot()+ geom_smooth(data = ele.speed.wood %&gt;% filter(var == &quot;v.pred2&quot;), aes(x = wood, y = mean, col = season, fill = season, lty = season), alpha = 0.2, size = 0.3)+ geom_pointrange(data = ele.speed.wood %&gt;% filter(var == &quot;v2&quot;), aes(x = wood, ymin = mean-ci, ymax = mean+ci, y = mean, col = season, shape = season), fill = &quot;white&quot;, position = position_dodge(width = 0.3), size = 0.4, stroke = 0.7)+ geom_rangeframe(data = data_frame(x=c(0,80),y=c(0.15,0.6)), aes(x,y))+ #facet_wrap(~var_name, scales = &quot;free_x&quot;)+ scale_color_brewer(palette = &quot;Set1&quot;)+ scale_fill_brewer(palette = &quot;Set1&quot;)+ scale_linetype_manual(values=c(2,1))+ scale_shape_manual(values= c(21,24))+ theme_few()+ theme(panel.border = element_blank(), legend.position = &quot;none&quot;)+ labs(x = &quot;Woody cover (%)&quot;, y = &quot;Speed (km/h)&quot;, title = &quot;(b)&quot;)+ scale_x_continuous(breaks = seq(0, 80, 20))+ scale_y_continuous(breaks = c(.15,.3,.45,.6), limits = c(NA, .6))+ coord_cartesian(ylim=c(.15,.6)) 3.4 Figure 4: Speed and temperature and woody cover half = 85/25.4; full = 180/25.4 # export fig for temp measures library(gridExtra) figure_04_speed = grid.arrange(fig_speed_temp, fig_speed_wood, nrow = 1) ggsave(figure_04_speed, filename = &quot;figs/figure_04_speed.pdf&quot;, height = half, width = full) library(magick) fig04 = magick::image_read_pdf(&quot;figs/figure_04_speed.pdf&quot;) fig04 (#fig:show_figure_04)Speed of elephant movement in relation to (a) collar temperature (at 2 ◦ C intervals) and (b) % woody cover (at 5 unit intervals) in the dry (red circles) and wet season (blue triangles). GAMM fit (lines) and 95% confidence intervals (vertical line ranges and shaded areas) are shown for each season separately. "],
["preliminary-data-preparation.html", "Section 4 Preliminary data preparation 4.1 Load libraries 4.2 Load data 4.3 Preliminary checks 4.4 Fix problematic coordinates 4.5 Data distribution in time 4.6 Elephants near the weather station", " Section 4 Preliminary data preparation This section prepares the raw data to be used in the main methods. 4.1 Load libraries # load libraries library(dplyr) library(purrr) library(lubridate) library(readr) library(glue) library(stringr) # spatial library(sf) # plotting library(ggplot2) library(ggthemes) library(viridis) 4.2 Load data # load the preliminary data ele.dry = read_csv(&quot;data/ele_data/ele.dry.csv&quot;) ele.wet = read_csv(&quot;data/ele_data/ele.wet.csv&quot;) # combine to form a single dataset with seasons assigned ele.dry$season = &quot;dry&quot; ele.wet$season = &quot;wet&quot; #&#39;rbind the data ele = bind_rows(ele.dry, ele.wet) # susbet columns and rename ele = ele %&gt;% select(id = ID, ref = REF, long = LONGITUDE, lat = LATITUDE, temp = TEMP, season, xutm = XUTM, yutm = YUTM, time = Date_time, landscape = landsca, land.val = VALUE, density = DENSITY, woody.density = `woody density`, veg.class = VEG_CLASS, gertcode = Gertcode, v = STEPLENGTH, angle = TURNANGLE, heading = BEARING, distw = dist_water, distr = Dist_river) #&#39;change time to posixct via char ele$time = as.POSIXct(as.character(ele$time), tz = &quot;SAST&quot;, format = &quot;%d-%m-%Y %H:%M&quot;) # add hour and change column types ele = ele %&gt;% mutate(hour = hour(time), season = as.factor(season), gertcode = as.factor(gertcode)) 4.3 Preliminary checks We suspect that rows are not ordered in time. Check for this and correct it. Save the resulting data as data/ele_total.csv. # check for the minimum time lag between points. this must be greater than 0 # negtive time lags indicate positions are not ordered by time ele %&gt;% split(ele$id) %&gt;% map_chr(function(l){ min(as.numeric(diff(l$time))) &gt; 0 }) # check for weird coordinates # what are the bounding boxes (xmin, xmax, ymin, ymax) of each ele ele %&gt;% group_by(id) %&gt;% summarise_at(vars(long, lat), list(min=min, max=max)) # now check for ridiculous trajectories if(!dir.exists(&quot;figs/tracks&quot;)){ dir.create(&quot;figs/tracks&quot;) } # get kruger kruger = st_read(&quot;data/kruger_clip/&quot;) %&gt;% `st_crs&lt;-`(4326) kruger_utm = kruger %&gt;% st_transform(32736) ele %&gt;% split(ele$id) %&gt;% map(function(a){ a = arrange(a, time) fig_a_utm = ggplot(kruger_utm)+ geom_sf(fill = NA)+ geom_path(data = a, aes(xutm, yutm), lwd = 0.1)+ theme_few()+ labs(x=NULL, y=NULL, title = unique(a$id), subtitle = &quot;UTM data&quot;) fig_a = ggplot(kruger)+ geom_sf(fill = NA)+ geom_path(data = a, aes(long, lat), lwd = 0.1)+ theme_few()+ labs(x=NULL, y=NULL, title = unique(a$id), subtitle = &quot;longlat data&quot;) fig = gridExtra::grid.arrange(fig_a, fig_a_utm, ncol = 2) ggsave(fig, filename = glue(&#39;figs/tracks/track_{unique(a$id)}.png&#39;)) }) Some elephants (239, 254, 255, 307, 308) have errored UTM coordinates which need to be ffixed. There are two issues: first, poor merging of the UTM converted coordinates with the parent data.frame at some stage prior to being processed for this paper (239 – 255). Second, two elephants, 307 and 308, seem to have had their UTM coordinates cropped to the limits of the Kruger shapefile, while the long-lat coordinates are preserved. knitr::include_graphics(c(&quot;figs/tracks/track_AM254.png&quot;, &quot;figs/tracks/track_AM307.png&quot;)) (#fig:show_ele_problems1)Problematic conversion of elephant tracking data coordinates from long-lat to UTM. (#fig:show_ele_problems2)Problematic conversion of elephant tracking data coordinates from long-lat to UTM. 4.4 Fix problematic coordinates # fix all elephant utm coordinates by doing a fresh transform ele = ele %&gt;% split(ele$id) %&gt;% map(function(l){ geo = select(l, time, long, lat) %&gt;% arrange(time) l = select(l, -xutm, -yutm) utm = st_as_sf(geo, coords = c(&quot;long&quot;, &quot;lat&quot;)) %&gt;% `st_crs&lt;-`(4326) %&gt;% st_transform(32736) %&gt;% st_coordinates() %&gt;% as_tibble() %&gt;% rename(xutm = &quot;X&quot;, yutm = &#39;Y&#39;) l = cbind(l, utm) }) # run time checks ele %&gt;% split(ele$id) %&gt;% map_chr(function(l){ min(as.numeric(diff(l$time))) &gt; 0 }) # examine tracks on a map prob_eles = filter(ele, id %in% c(&quot;AM239&quot;, &quot;Am254&quot;, &quot;AM255&quot;, &quot;AM307&quot;, &quot;AM308&quot;)) fig_fixed_eles = ggplot(kruger_utm)+ geom_sf(fill = NA)+ geom_path(data = prob_eles, aes(x=xutm, y=yutm, group = id, col = id), lwd = 0.1)+ theme_few()+ labs(x=NULL, y=NULL) # save figure ggsave(fig_fixed_eles, filename = glue(&#39;figs/tracks/track_fixed_eles.png&#39;)) knitr::include_graphics(&quot;figs/tracks/track_fixed_eles.png&quot;) (#fig:show_ele_fixed)Problem elephant coordinates are now fixed. 4.4.1 Save fixed coordinates write_csv(ele, path = &quot;data/elephant_data.csv&quot;) 4.5 Data distribution in time 4.5.1 Seasonal summary # how many positions per elephant per year and season data_season_summary = ele %&gt;% group_by(year_season = paste(year(time), season, sep = &quot; &quot;)) %&gt;% count(id) # make figure fig_season_summary = ggplot(data_season_summary)+ geom_tile(aes(x = id, y = year_season, fill = n))+ scale_fill_viridis()+ theme_few()+ labs(x = &quot;elephant id&quot;,y = &quot;year &amp; season&quot;, fill = &quot;positions&quot;)+ coord_flip() # save figure ggsave(fig_season_summary, filename = &quot;figs/fig_season_summary.png&quot;, width = 8, height = 6) # import and show knitr::include_graphics(&quot;figs/fig_season_summary.png&quot;) 4.5.2 Monthly summary # positions per elephant per month and year data_month_summary = group_by(ele, year_month = glue(&#39;{year(time)} {str_pad(month(time), width = 2, pad = &quot;0&quot;)}&#39;)) %&gt;% count(id) # make figure fig_month_summary = ggplot(data_month_summary)+ geom_tile(aes(x = id, y = year_month, fill = n))+ scale_fill_viridis()+ theme_few()+ theme(axis.text.x = element_text(size = 4))+ labs(fill = &quot;positions&quot;, x = &quot;Individual&quot;, y = &quot;Year month&quot;)+ coord_flip() # save figure ggsave(fig_month_summary, filename = &quot;figs/fig_month_summary.png&quot;, width = 12, height = 6) # import and show knitr::include_graphics(&quot;figs/fig_month_summary.png&quot;) 4.6 Elephants near the weather station Which elephants are within 10 km of the weather station at Skukuza, and when? 4.6.1 Load Skukuza The weather station at Skukuza (24.9 S, 31.5 E) is our source for ambient temperature data. # load skukuza and make sf skukuza = read_csv(&quot;data/skukuza.csv&quot;) skukuza = st_as_sf(skukuza, coords = c(&quot;long&quot;, &quot;lat&quot;)) %&gt;% `st_crs&lt;-`(4326) %&gt;% st_transform(32736) # get buffer around skukuza skz_buf = st_buffer(skukuza, dist = 10000) 4.6.2 Select elephants within 10 km # make eles sf and crop by buffer ele_sf = st_as_sf(ele[, c(&quot;long&quot;, &quot;lat&quot;)], coords = c(&quot;long&quot;, &quot;lat&quot;)) %&gt;% `st_crs&lt;-`(4326) %&gt;% st_transform(32736) ele_keep = st_contains(skz_buf, ele_sf) ele_keep = unlist(ele_keep) # eles to keep ele_tower = ele[ele_keep,] 4.6.3 Get distribution over time #&#39;which eles are here and over which months? data_tower_summary = group_by(ele_tower, year_month = glue(&#39;{year(time)} {str_pad(month(time), width = 2, pad = &quot;0&quot;)}&#39;)) %&gt;% count(id) # make figure fig_tower_summary = ggplot(data_tower_summary)+ geom_tile(aes(x = id, y = year_month, fill = n))+ scale_fill_viridis(option=&quot;C&quot;)+ theme_few()+ labs(fill = &quot;positions&quot;, x = &quot;elephant&quot;, y = &quot;year month&quot;)+ coord_flip() # save figure ggsave(fig_tower_summary, filename = &quot;figs/fig_tower_summary.png&quot;, width = 10, height = 4) # import and show knitr::include_graphics(&quot;figs/fig_tower_summary.png&quot;) "],
["getting-spatial-data.html", "Section 5 Getting spatial data 5.1 Load libraries 5.2 Getting temperature data 5.3 Getting elevation data 5.4 Reproject data to UTM 36S", " Section 5 Getting spatial data 5.1 Load libraries # load libraries library(purrr) library(ggplot2) This section looks at using Google Earth Engine (Gorelick et al. 2017) to retrieve remote sensing data and process it for use. This code is in Javascript. The cropped raster can be saved to your Google Drive. Retrieval of the raster from Drive is not covered. The data are much too large to be rendered here, and their inspection is also not covered. 5.2 Getting temperature data Code to get 30m thermal data from LANDSAT-5 (Schmidt et al. 2013). // get extent and landsat 5 data var geometry = /* color: #ff3d3d */ee.Geometry.Polygon( [[[77.26686452041235, 13.344492655458648], [77.26803063514615, 12.69020162411501], [78.31220864869454, 12.698000169170149], [78.31998125667042, 13.342950249131635]]]), table = ee.FeatureCollection(&quot;users/pratik_unterwegs/ele_ext&quot;), table2 = ee.FeatureCollection(&quot;users/pratik_unterwegs/kruger_clip&quot;), l5 = ee.ImageCollection(&quot;LANDSAT/LT05/C01/T1_SR&quot;); //define func var crop = function(x){ var image = x. clip(table). divide(10). subtract(273); return image; } // filter landsat 5 data for time, cloud cover, and thermal band var filtered = l5.filterDate(&#39;2007-08-01&#39;, &#39;2009-08-30&#39;). filterMetadata(&#39;CLOUD_COVER&#39;, &#39;less_than&#39;, 10). select(&#39;B6&#39;). map(crop). mean(); var rgb_viz = {min: 20, max: 35, bands:[&#39;B6&#39;], palette: [&quot;#0D0887FF&quot;, &quot;#4C02A1FF&quot;, &quot;#7E03A8FF&quot;, &quot;#A92395FF&quot;, &quot;#CC4678FF&quot;, &quot;#E56B5DFF&quot;,&quot;#F89441FF&quot;, &quot;#FDC328FF&quot;, &quot;#F0F921FF&quot;] }; Map.addLayer(filtered, rgb_viz, &#39;kruger_temp&#39;); // export to google drive Export.image.toDrive({ image: filtered, description: &#39;kruger_temperature&#39;, scale: 30, region: table.geometry()}); 5.3 Getting elevation data Code to get 30m elevation data from SRTM (Farr et al. 2007) using the Google Earth Engine Javascript API. This data was acquired and later not used. //load SRTM data and elephant extent var image = ee.Image(&quot;USGS/SRTMGL1_003&quot;), table = ee.FeatureCollection(&quot;users/pratik_unterwegs/ele_ext&quot;), ext = ee.FeatureCollection(&quot;users/pratik_unterwegs/ele_ext&quot;), geometry = ee.Geometry.MultiPoint(); //filter 30m DEM for the polygon var srtm_clip = image.clip(ext.geometry()); Map.addLayer(table); //get slope var srtm_slope = ee.Terrain.slope(srtm_clip); //check elevation map Map.addLayer(srtm_clip, {min: 0, max :500, palette: [&quot;#00A600FF&quot;, &quot;#2DB600FF&quot;, &quot;#63C600FF&quot;, &quot;#A0D600FF&quot;, &quot;#E6E600FF&quot;, &quot;#E8C32EFF&quot;, &quot;#EBB25EFF&quot;, &quot;#EDB48EFF&quot;, &quot;#F0C9C0FF&quot;, &quot;#F2F2F2FF&quot; ]}, &#39;elevation&#39;); // check slope map Map.addLayer(srtm_slope, {min: 0, max :10, palette: [&quot;#00A600FF&quot;, &quot;#2DB600FF&quot;, &quot;#63C600FF&quot;, &quot;#A0D600FF&quot;, &quot;#E6E600FF&quot;, &quot;#E8C32EFF&quot;, &quot;#EBB25EFF&quot;, &quot;#EDB48EFF&quot;, &quot;#F0C9C0FF&quot;, &quot;#F2F2F2FF&quot; ]}, &#39;slope&#39;); //export to file Export.image.toDrive({ image: srtm_clip, description: &#39;kruger_elevation&#39;, scale: 30, region: table.geometry() }); Export.image.toDrive({ image: srtm_slope, description: &#39;kruger_slope&#39;, scale: 30, region: table.geometry() }); 5.4 Reproject data to UTM 36S # use gdalwarp from gdalutils library(gdalUtils) library(stringr) library(glue) # list the files and warp them kruger_terrain = list.files(&quot;data&quot;, pattern = &quot;kruger_&quot;, full.names = TRUE) map(kruger_terrain, function(df){ name = str_split(df, &quot;.tif&quot;, simplify = TRUE)[,1] gdalwarp(srcfile = df, dstfile = as.character(glue(&#39;{name}_UTM.tif&#39;)), t_srs = &quot;+proj=utm +zone=36 +south +datum=WGS84 +units=m +no_defs&quot;, tr = c(30,30)) }) "]
]
