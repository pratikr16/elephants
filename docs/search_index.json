[
["index.html", "Fine-Scale Tracking of Ambient Temperature and Movement Reveals Shuttling Behavior of Elephants to Water Section 1 About 1.1 Contact 1.2 Data access 1.3 Data processing", " Fine-Scale Tracking of Ambient Temperature and Movement Reveals Shuttling Behavior of Elephants to Water Maria Thaker, Pratik R. Gupte, Herbert HT Prins, Rob Slotow, and Abi T. Vanak January 2019 Section 1 About This is the source code for the publication Thaker M, Gupte PR, Prins HHT, et al (2019) Fine-Scale Tracking of Ambient Temperature and Movement Reveals Shuttling Behavior of Elephants to Water. Front Ecol Evol 7:. doi: 10.3389/fevo.2019.00004 1.1 Contact Corresponding author Dr. Maria Thaker Centre for Ecological Sciences, Indian Institute of Science. Email: m.thaker@iisc.ac.in Code maintainer Pratik R. Gupte Groningen Institute for Evolutionary Life Sciences, University of Groningen. Email: p.r.gupte@rug.nl 1.2 Data access The tracking dataset collected for use in this work is available from Movebank: https://doi.org/10.5441/001/1.403h24q5 Other data used in this study are cited in the text. 1.3 Data processing The data processing for this project is described in the following sections. Navigate through them using the links in the sidebar. "],
["collar-temperature-and-ambient-temperature.html", "Section 2 Collar temperature and ambient temperature 2.1 Load libraries 2.2 Load tracking and temperature data 2.3 Select ele data near tower 2.4 Combine collar and ambient temp 2.5 Exploring collar and ambient temp 2.6 Model collar and ambient temp 2.7 Global Bland-Altman test 2.8 Figure 3: Collar and ambient temperature", " Section 2 Collar temperature and ambient temperature Here we model the relationship between the temperature reported by inbuilt temperature sensors on the elephants’ GPS collars, and the ambient temperature recorded at Skukuza. For this comparison, we will only use data from positions recorded within 10 km of the weathe weather tower at Skukuza. 2.1 Load libraries # load libraries library(dplyr) library(purrr) library(lubridate) library(readr) library(readxl) library(glue) library(stringr) library(forcats) # spatial library(sf) # plotting library(ggplot2) library(ggthemes) library(viridis) # custom funcs ci = function(x) 1.96*sd(x, na.rm = T)/sqrt(length(x)) 2.2 Load tracking and temperature data Read the tracking data from a number of elephants from 2006 – 2011. Read in the ambient temperature for approximately the same range, 2007 – 2010. Handle the date and time columns correctly using lubridate and floor the time to the nearest half hour. # read in data saved as csv from an excel file data = read_csv(&quot;data/AllEles2011_UTM.csv&quot;) # read in temperature data and select relevant cols amb_temp = read_csv(&quot;data/skukuza_tower_temp.csv&quot;) %&gt;% `colnames&lt;-`(c(&quot;date&quot;,&quot;time&quot;,&quot;prop_time&quot;,&quot;col4&quot;,&quot;temp.a&quot;,&quot;col6&quot;,&quot;col7&quot;)) %&gt;% select(date, prop_time, temp.a) %&gt;% mutate(date = fast_strptime(date, format = &quot;%d/%m/%Y&quot;, lt = F), time = as.numeric(date) + prop_time*24*3600, time = as.POSIXct(time, origin = &quot;1970-01-01&quot;), time = floor_date(time, unit = &quot;30 minutes&quot;)) %&gt;% select(time, temp.a) # read in tower location skukuza = read_csv(&quot;data/skukuza.csv&quot;) %&gt;% st_as_sf(coords = c(&quot;long&quot;,&quot;lat&quot;), crs = 4326) %&gt;% st_transform(st_crs(32736)) # get buffer around skukuza skz_buf = st_buffer(skukuza, dist = 10000) 2.3 Select ele data near tower 2.3.1 Convert to sf and filter # make ele data spatial data_sf = st_as_sf(data, coords = c(&quot;XUTM&quot;,&quot;YUTM&quot;)) st_crs(data_sf) = 32736 # which eles are inside the buffer data_keep = st_contains(skz_buf, data_sf) data_keep = unlist(data_keep) # eles to keep data_tower = data[data_keep,] 2.3.2 Clean filtered data Here, process the date and time by converting the Date_Time column to POSIXct. Then convert time to POSIXct by adding the proportional daily time to the numeric date. Finally, round the time to the nearest half hour. As a sanity check, do the increments of Time_Number follow the increments in time? #&#39;clean ele data data.tow.clean = data_tower %&gt;% mutate(date = fast_strptime(Date_Time, format = &quot;%d/%m/%Y&quot;, lt = F), time = as.POSIXct(as.numeric(date) + TimeNumber*24*60*60, origin = &quot;1970-01-01&quot;), time = floor_date(time, &quot;30 min&quot;)) %&gt;% rename(temp = TempC) 2.4 Combine collar and ambient temp 2.4.1 Prepare data for Bland-Altman Join the elephant data within 10 km of the tower with ambient temperature data from the tower by the time column. Exploring the data reveals that ambient temperature data records NA as -9999. Filter the data to exclude these values. #&#39;match ele and flux tower data.tow.clean.ba = data.tow.clean %&gt;% select(id = UnitID, time, temp, season = Season) %&gt;% left_join(amb_temp) # filter combined data data.tow.clean.ba = data.tow.clean.ba %&gt;% filter(temp.a &gt;= -5, !is.na(temp), !is.na(temp.a)) %&gt;% mutate(hour = hour(time), season = as_factor(season), temp = as.numeric(temp)) 2.4.2 Prepare Fig. 3 (A): Daily temperature trend # make figure of temps per hour of day data_fig3a = data.tow.clean.ba %&gt;% group_by(hour, season) %&gt;% summarise_at(vars(temp, temp.a), list(mean = mean, ci = ci)) fig_temp_measure_hour = ggplot(data_fig3a, aes(x = hour))+ geom_rangeframe(data = data_frame(x = c(0,23), y=c(15,40)), aes(x,y))+ geom_path(aes(y = temp_mean, col = season), lty = 1)+ geom_path(aes(y = temp.a_mean, col = season), lty=2)+ geom_ribbon(aes(ymin = temp_mean - temp_ci, ymax = temp_mean + temp_ci, group = season, fill = season), alpha = 0.2)+ geom_ribbon(aes(ymin = temp.a_mean - temp.a_ci, ymax = temp.a_mean + temp.a_ci, group = season, fill = season), alpha = 0.2)+ scale_colour_brewer(palette = &quot;Set1&quot;)+ scale_fill_brewer(palette = &quot;Set1&quot;)+ scale_x_continuous(breaks = c(0,4,8,12,16,20,23))+ scale_y_continuous(breaks = seq(15,40,5))+ theme_few()+ theme(legend.position = &quot;none&quot;, panel.border = element_blank(), axis.text = element_text(size = 8), axis.title = element_text(size = 8))+ coord_cartesian(xlim = c(0,23))+ labs(x = &quot;Hour of day&quot;, y = &quot;Temperature (°C)&quot;, title = &quot;(a)&quot;) 2.5 Exploring collar and ambient temp 2.5.1 Prepare data for models # load statistical package lme4 library(lme4) mean_wo_na = function(x) mean(x, na.rm=T) sd_wo_na = function(x) sd(x, na.rm = T) # random effects model for within individual and hour std deviation # get the mean data ele.BA.data = ungroup(data.tow.clean.ba) %&gt;% mutate(diff = temp-temp.a, mean.temp = (temp+temp.a)/2) %&gt;% mutate(hour.plot = paste(str_pad(hour, 2, side = &quot;left&quot;, pad = &quot;0&quot;), &quot;:00&quot;, sep = &quot;&quot;)) 2.5.2 Run models per hour # run mods in each hour ele.BA.mods = ungroup(ele.BA.data) %&gt;% split(ele.BA.data$hour.plot) %&gt;% map(function(x){ lmer(temp ~ temp.a + season + (1|id), data = x) }) # prepare predict data ele.pred.data = ele.BA.data %&gt;% split(ele.BA.data$hour.plot) # predict from the model on prepared data ele.tempmod.fit = map2(ele.pred.data, ele.BA.mods, function(x,y){ x %&gt;% mutate(pred = predict(y, newdata = x, type = &quot;response&quot;, se.fit = T)) }) %&gt;% bind_rows() 2.5.3 Prepare data for plotting Extract the variance-correlation components from the hour-wise models using lme4::VarCorr. Get the standard deviation for each hour. # summarise model data using multiple maps ele.ba.summary = ele.BA.mods %&gt;% map(.f = VarCorr) %&gt;% map(function(x){ data_frame(sd_id = as.data.frame(x) %&gt;% .$sdcor %&gt;% sum()) }) %&gt;% bind_rows() %&gt;% mutate(hour = 0:23) %&gt;% mutate(hour.plot = paste(str_pad(hour, 2, side = &quot;left&quot;, pad = &quot;0&quot;), &quot;:00&quot;, sep = &quot;&quot;)) # get the mean differences from the data prepared for the model # join to the hour-wise standard deviation mean_diff = ele.BA.data %&gt;% group_by(hour.plot) %&gt;% summarise(diff = mean(diff, na.rm = T)) %&gt;% left_join(ele.ba.summary) 2.5.4 Prepare Bland-Altman plots Plot the hour-wise relationship between collar temperature and ambient temperature, and the hour-wise Bland-Altman plots. #&#39;make appendix figure a fig_temp_rel_hr = ggplot()+ geom_rangeframe(data = data_frame(x=c(10,40), y = c(0,40)), aes(x,y))+ geom_point(data = ele.BA.data, aes(x = temp.a, y = temp), size = 0.1, alpha = 0.2)+ geom_smooth(data = ele.tempmod.fit, aes(x = temp.a, y = pred), method = &quot;glm&quot;, col = &quot;steelblue&quot;)+ geom_abline(slope = 1, lty = 2, col = 1, lwd = 0.2)+ scale_x_continuous(breaks = c(10,25,40))+ facet_wrap(~hour.plot, nrow = 4)+ theme_few()+ coord_fixed()+ theme(panel.border = element_blank())+ labs(x = &quot;Ambient temperature (°C)&quot;, y = &quot;Collar temperature (°C)&quot;, title = &quot;(a)&quot;) #&#39;appendix figure b fig_ba_hour = ggplot()+ geom_rangeframe(data = data_frame(x=c(10,40), y = c(-10,30)), aes(x,y))+ geom_point(data = ele.BA.data, aes(x = mean.temp, y = diff), size = 0.1, alpha = 0.2)+ geom_abline(slope = 0, lty = 2, col = 1, lwd = 0.2)+ geom_hline(data = mean_diff, aes(yintercept = diff), col = &quot;brown&quot;)+ geom_hline(data = mean_diff, aes(yintercept = 1.96*sd_id + diff), col = &quot;steelblue&quot;)+ geom_hline(data = mean_diff, aes(yintercept = diff - 1.96*sd_id), col = &quot;steelblue&quot;)+ #coord_cartesian(ylim = c(0,40), xlim = c(0,40))+ scale_y_continuous(breaks = seq(-10,30, 10))+ scale_x_continuous(breaks = c(10,25,40))+ theme_few()+ theme(panel.background = element_blank())+ facet_wrap(~hour.plot, nrow = 4)+ coord_fixed()+ theme(panel.border = element_blank())+ labs(x = &quot;Mean (amb &amp; collar) temp. (°C)&quot;, y = &quot;Collar - amb. temp. (°C)&quot;, title = &quot;(b)&quot;) fig_hourwise_collar_ambient = gridExtra::grid.arrange(fig_temp_rel_hr, fig_ba_hour, nrow = 1) ggsave(fig_hourwise_collar_ambient, filename = &quot;figs/fig_hourwise_collar_ambient.png&quot;, device = png(), height = 180/25.4, width = 1.5*180*1.2/25.4, dpi = 300) 2.6 Model collar and ambient temp 2.6.1 LMM collar and ambient temp Run a global linear mixed effects model for collar temperature as a function of ambient temperature. Write the model summary to a text file. # run global lmm for collar and ambient temperature mod.temp = lmer(temp ~ temp.a + season + (1|hour) + (1|id), data = data.tow.clean.ba) # write model summary if(!dir.exists(&quot;data/model_output&quot;)){ dir.create(&quot;data/model_output&quot;) } # clear old output if(file.exists(&quot;data/model_output/model_collar_amb_temp.txt&quot;)){ file.remove(&quot;data/model_output/model_collar_amb_temp.txt&quot;) } R.utils::captureOutput(summary(mod.temp), file = &quot;data/model_output/model_collar_amb_temp.txt&quot;, append = TRUE) R.utils::captureOutput(car::Anova(mod.temp), file = &quot;data/model_output/model_collar_amb_temp.txt&quot;, append = TRUE) Print the model summary. cat(readLines(&quot;data/model_output/model_collar_amb_temp.txt&quot;), sep = &quot;\\n&quot;) Linear mixed model fit by REML [&#39;lmerMod&#39;] Formula: temp ~ temp.a + season + (1 | hour) + (1 | id) Data: data.tow.clean.ba REML criterion at convergence: 77689.3 Scaled residuals: Min 1Q Median 3Q Max -4.2505 -0.6336 0.0434 0.6518 5.0781 Random effects: Groups Name Variance Std.Dev. hour (Intercept) 12.825 3.581 id (Intercept) 3.865 1.966 Residual 7.473 2.734 Number of obs: 15982, groups: hour, 24; id, 4 Fixed effects: Estimate Std. Error t value (Intercept) 13.566910 1.254904 10.81 temp.a 0.610849 0.006104 100.07 seasonDry -1.073253 0.051963 -20.65 Correlation of Fixed Effects: (Intr) temp.a temp.a -0.117 seasonDry -0.067 0.365 Analysis of Deviance Table (Type II Wald chisquare tests) Response: temp Chisq Df Pr(&gt;Chisq) temp.a 10014.04 1 &lt; 2.2e-16 *** season 426.59 1 &lt; 2.2e-16 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 2.6.2 Get variance components # calculate variance components and print # variance of random effects var_eff_hour = as.numeric(VarCorr(mod.temp))[1] var_eff_Id = as.numeric(VarCorr(mod.temp))[2] # residual var_res = as.numeric(attr(VarCorr(mod.temp), &quot;sc&quot;)^2) # fixed effects only var_fix = var(predict(lm(temp ~ temp.a + season, data = data.tow.clean.ba))) # total data variance var_tot = var(data.tow.clean.ba$temp) # proportional variances p_var = c(var_eff_hour, var_eff_Id, var_res, var_fix)*100/var_tot # make data frame and save mod_collar_amb_temp_variance = data_frame(component = c(&quot;hour&quot;, &quot;id&quot;, &quot;residual&quot;, &quot;fixed_effects&quot;), variance = c(var_eff_hour, var_eff_Id, var_res, var_fix), percentage = p_var) # write to file write_csv(mod_collar_amb_temp_variance, path = &quot;data/model_output/mod_collar_amb_temp_variance.txt&quot;) Print the variance components of the model. variance_comp_temp_amb = read_csv(&quot;data/model_output/mod_collar_amb_temp_variance.txt&quot;) knitr::kable(variance_comp_temp_amb) component variance percentage hour 12.824898 27.160790 id 3.865104 8.185584 residual 7.472789 15.826000 fixed_effects 31.916336 67.592966 2.6.3 Prepare Figure 3 (B): Collar ~ ambient temperature Prepare a figure of the relationship between collar temperature and ambient temperature. This forms figure 3B of the manuscript. # plot figure of mean relationship collar and ambient temp fig_temp_rel_data &lt;- data.tow.clean.ba %&gt;% group_by(season, temp.a = round(temp.a)) %&gt;% summarise_at(vars(temp), list(temp_mean = mean, temp_ci = ci)) fig_temp_measure_relation &lt;- ggplot()+ geom_smooth(data = fig_temp_rel_data, aes(x = temp.a, y = temp_mean, group = season, col = season, fill = season), method = &quot;glm&quot;, se =T, alpha = 0.2,lwd = 0.5)+ geom_pointrange(data = fig_temp_rel_data, aes(x = temp.a, y = temp_mean, ymin = temp_mean-temp_ci , ymax = temp_mean+temp_ci, shape = season, col = season), position = position_dodge(width = 0.5), fill = &quot;white&quot;, size = 0.1, stroke = 0.4)+ geom_rangeframe(data = data_frame(x = c(5,40), y = c(4,44)), aes(x,y))+ geom_abline(slope = 1, lty = 2)+ scale_colour_brewer(palette = &quot;Set1&quot;)+ scale_fill_brewer(palette = &quot;Set1&quot;)+ scale_shape_manual(values = c(21, 24))+ scale_x_continuous(breaks = seq(5,40,5))+ scale_y_continuous(breaks = seq(4,44,8))+ coord_cartesian(xlim=c(5,40), ylim = c(5,44))+ theme_few()+ theme(panel.border = element_blank(), legend.position = &quot;none&quot;, axis.text = element_text(size = 8), axis.title = element_text(size = 8))+ labs(x = &quot;Ambient temperature (°C)&quot;, y = &quot;Collar temperature (°C)&quot;, title = &quot;(b)&quot;) 2.7 Global Bland-Altman test Prepare a global Bland Altman test and associated plots. 2.7.1 Prepare data for global Bland-Altman # get data for global BA plot ele.BA.data = ele.BA.data %&gt;% filter(!is.na(temp), !is.na(temp.a)) %&gt;% ungroup() %&gt;% group_by(id, hour, season) %&gt;% summarise_at(vars(temp, temp.a), funs(mean)) %&gt;% mutate(mean.measures = (temp+temp.a)/2, diff.measures = temp-temp.a) %&gt;% ungroup() %&gt;% group_by(mean.measures = round(mean.measures), season) %&gt;% summarise_at(vars(diff.measures), funs(mean)) 2.7.2 GAMM for Bland-Altman trend # run a gamm of differences vs mean for the BA data library(mgcv) BA.gam = gam(diff.measures ~ s(mean.measures, by = season), data = ele.BA.data) # write summary to file and then read and show # clear old output if(file.exists(&quot;data/model_output/model_gamm_BA.txt&quot;)){ file.remove(&quot;data/model_output/model_gamm_BA.txt&quot;) } R.utils::captureOutput(summary(BA.gam), file = &quot;data/model_output/model_gamm_BA.txt&quot;, append = TRUE) # get model predictions ele.BA.data$pred = predict(BA.gam, type = &quot;response&quot;, newdata = ele.BA.data, se.fit = T)[[1]] ele.BA.data$se = predict(BA.gam, type = &quot;response&quot;, newdata = ele.BA.data, se.fit = T)[[2]] Print the GAMM summary. cat(readLines(&quot;data/model_output/model_gamm_BA.txt&quot;), sep = &quot;\\n&quot;) Family: gaussian Link function: identity Formula: diff.measures ~ s(mean.measures, by = season) Parametric coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 4.5342 0.2535 17.89 3.82e-15 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Approximate significance of smooth terms: edf Ref.df F p-value s(mean.measures):seasonWet 1.593 1.980 11.36 0.00025 *** s(mean.measures):seasonDry 2.012 2.509 16.46 7.09e-06 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 R-sq.(adj) = 0.704 Deviance explained = 74.4% GCV = 2.0248 Scale est. = 1.6918 n = 28 2.7.3 Prepare Fig. 3 (C): Bland-Altman plot # prepare global bland altman figure figBArevised = ggplot(ele.BA.data)+ geom_ribbon(aes(x = mean.measures, ymin = pred-se, ymax = pred+se, fill = season), alpha = 0.2)+ geom_line(aes(x = mean.measures, y = pred, col = season), lty = 2)+ geom_point(aes(x = mean.measures, y = diff.measures, col = season, shape = season), fill = &quot;white&quot;, size = 1,stroke = 0.5)+ scale_color_brewer(palette = &quot;Set1&quot;, direction = -1)+ scale_fill_brewer(palette = &quot;Set1&quot;)+ scale_shape_manual(values = c(24,21))+ geom_rangeframe(data = data_frame(x=c(15,35), y = c(-5,20)), aes(x,y))+ geom_hline(yintercept = c(0,mean(mean_diff$diff), mean(mean_diff$diff) + 1.96*mean(mean_diff$sd_id), mean(mean_diff$diff) - 1.96*mean(mean_diff$sd_id)), lty = c(2,1,1,1), lwd = c(0.2, 0.4,0.4,0.4), col = c(&quot;black&quot;,&quot;brown&quot;,&quot;steelblue&quot;,&quot;steelblue&quot;))+ theme_few()+ theme(legend.position = &quot;none&quot;, panel.border = element_blank(), axis.text = element_text(size = 8), axis.title = element_text(size = 8))+ scale_y_continuous(breaks = c(seq(-5,20, 5)))+ labs(x = &quot;Mean (collar &amp; amb.) temp (°C)&quot;, y = &quot;Collar temp. - amb. temp. (°C)&quot;, title = &quot;(c)&quot;) 2.7.4 Write hourly model summaries to file Gather model output for temperature models per hour and write to file. # hourly model output # this is complicated code, please don&#39;t do it this way ele.temp.mods.summary = ele.BA.mods %&gt;% map(summary) %&gt;% map(function(x){ x$coefficients %&gt;% as.data.frame() %&gt;% select(Estimate, `t value`) %&gt;% mutate(predictor = rownames(.)) %&gt;% tidyr::gather(lmm_output, value, -predictor) %&gt;% filter(predictor != (&quot;(Intercept)&quot;)) %&gt;% mutate(value = plyr::round_any(value, 0.01)) %&gt;% tidyr::spread(lmm_output, value)}) %&gt;% bind_rows() %&gt;% mutate(hour = rep(0:23, each = 2), predictor = ifelse(predictor != &quot;temp.a&quot;, &quot;season&quot;, predictor)) %&gt;% left_join(map(ele.BA.mods, function(x){ car::Anova(x) %&gt;% as.data.frame() %&gt;% mutate(predictor = rownames(.)) %&gt;% rename(p_value = `Pr(&gt;Chisq)`) %&gt;% select(-Df)}) %&gt;% bind_rows() %&gt;% mutate(hour = rep(0:23, each = 2), Chisq = plyr::round_any(Chisq, 0.1), p_value = plyr::round_any(p_value, 0.001))) # export to csv write_csv(ele.temp.mods.summary, path = &quot;data/model_output//ele_temp_mods_summary.txt&quot;) 2.8 Figure 3: Collar and ambient temperature half = 85/25.4; full = 180/25.4 # export fig for temp measures library(gridExtra) figure_03_temperature_sources = grid.arrange(fig_temp_measure_hour, fig_temp_measure_relation, figBArevised, nrow = 1) ggsave(figure_03_temperature_sources, filename = &quot;figs/figure_03_temperature_sources.pdf&quot;, height = half, width = full) library(magick) fig03 = magick::image_read_pdf(&quot;figs/figure_03_temperature_sources.pdf&quot;) fig03 (#fig:show_figure_03)(a) Mean collar temperature (solid lines) and measured ambient temperature from Skukuza flux tower (dashed lines) at each hour of day in each season (dry: red lines, wet: blue lines) over the study period. Ninety-Five percent confidence intervals (CI) about each line are shaded. (b) Correlation between mean collar temperature from elephants within 10 km of the Skukuza flux tower (from n = 3 elephants) and time-matched ambient temperatures measured by the flux tower in each season (dry: red circles, wet: blue triangles). The dashed line denotes the line of identity where collar temperature equals ambient temperature. Bars represent 95% CI at each point. (c) Bland-Altman limits of agreement plot comparing collar temperatures and ambient temperatures from the Skukuza flux tower, accounting for repeated measures of individual elephants and hour of day (n = 28,853 total comparisons). The bias between the two measures at each mean temperature is marked by symbols colored by season (dry: red circles, wet: blue triangles). The black dashed line marks zero difference between the two measures. The upper and lower limits of agreement are shown as the standard normal deviate (1.96) times the standard deviation due to elephant identity, and are marked by solid blue lines, while the mean difference in measures is marked by the solid red line. "],
["speed-and-collar-temperature.html", "Section 3 Speed and collar temperature 3.1 Load libraries 3.2 Load data from sources 3.3 Speed and temperature 3.4 Figure 4: Speed and temperature and woody cover", " Section 3 Speed and collar temperature Here we look at the relationship between elephant speed and collar temperature, as well as some other relevant factors that we think might influence elephant movement. 3.1 Load libraries # load libraries library(dplyr) library(purrr) library(lubridate) library(readr) # stats library(mgcv) # spatial library(sf) library(raster) # plotting library(ggplot2) library(ggthemes) library(viridis) # custom funcs ci = function(x) 1.96*sd(x, na.rm = T)/sqrt(length(x)) 3.2 Load data from sources Load the tracking data and the transformed slope data. # read in eles as csv data = read_csv(&quot;data/elephant_data.csv&quot;) 3.3 Speed and temperature 3.3.1 Run GAMM speed ~ temperature # make id a factor data$id = as.factor(data$id) data$season = as.factor(data$season) # run a GAMM using the mgcv package mod.speed = bam(v ~ s(temp, k = 4) + season + woody.density + s(id, bs = &quot;re&quot;) + s(hour, bs = &quot;re&quot;), data = data) # print model summary to file if(!dir.exists(&quot;data/model_output&quot;)){ dir.create(&quot;data/model_output&quot;) } if(file.exists(&quot;data/model_output/model_gamm_speed.txt&quot;)){ file.remove(&quot;data/model_output/model_gamm_speed.txt&quot;) } R.utils::captureOutput(summary(mod.speed), file = &quot;data/model_output/model_gamm_speed.txt&quot;, append = TRUE) Print the GAMM summary. cat(readLines(&quot;data/model_output/model_gamm_speed.txt&quot;), sep = &quot;\\n&quot;) Family: gaussian Link function: identity Formula: v ~ s(temp, k = 4) + season + woody.density + s(id, bs = &quot;re&quot;) + s(hour, bs = &quot;re&quot;) Parametric coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 252.55538 5.20079 48.56 &lt;2e-16 *** seasonwet 16.48085 0.86423 19.07 &lt;2e-16 *** woody.density -1.60256 0.03278 -48.89 &lt;2e-16 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Approximate significance of smooth terms: edf Ref.df F p-value s(temp) 2.995 3 4716.1 &lt;2e-16 *** s(id) 12.890 13 131.2 &lt;2e-16 *** s(hour) 0.991 1 112.6 &lt;2e-16 *** --- Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 R-sq.(adj) = 0.0667 Deviance explained = 6.68% fREML = 1.9511e+06 Scale est. = 52787 n = 284572 3.3.2 Prepare speed ~ temp plot data # prepare data for plotting ele.speed.temp = data %&gt;% mutate(v.pred = predict(mod.speed, newdata = ., scale = &quot;response&quot;, allow.new.levels = T), temp = plyr::round_any(temp,2)) %&gt;% ungroup() %&gt;% group_by(season, temp) %&gt;% summarise(v.mean = mean(v), v.sd = sd(v), n.v = length(v), pred.mean = mean(v.pred, na.rm = T), pred.sd=sd(v.pred, na.rm = T), pred.n = length(v.pred)) %&gt;% mutate(v.ci = qnorm(0.975)*v.sd/sqrt(n.v), ci.pred = qnorm(0.975)*pred.sd/sqrt(pred.n)) 3.3.3 Prepare Figure 4 (A): Speed and temperature # figure for speed and temperature fig_speed_temp = ele.speed.temp %&gt;% filter(temp %in% 10:40) %&gt;% ggplot()+ geom_rangeframe(data = data_frame(x=c(10,40), y = c(0.15,0.6)),aes(x,y))+ geom_smooth(aes(x = temp, y = pred.mean*2/1e3, col = season, fill = season, lty = season), alpha = 0.2, lwd = 0.5)+ geom_pointrange(aes(x = temp, y = v.mean*2/1e3, ymin = (v.mean-v.ci)*2/1e3, ymax = (v.mean+v.ci)*2/1e3, col = season, shape = season), fill = &quot;white&quot;, size = 0.4, stroke =0.7, lty = 1, position = position_dodge(width = 0.3))+ scale_fill_brewer(palette = &quot;Set1&quot;)+ scale_color_brewer(palette = &quot;Set1&quot;)+ scale_shape_manual(values=c(21,24))+ scale_linetype_manual(values=c(&quot;dashed&quot;,&quot;solid&quot;))+ theme_few()+ theme(panel.border = element_blank(), legend.position = &quot;none&quot;)+ coord_cartesian(ylim=c(0.15,0.6))+ scale_y_continuous(breaks = seq(.15,.6,.15))+ labs(x = &quot;Collar temperature (°C)&quot;, y = &quot;Speed (km/h)&quot;, col = &quot;Season&quot;, fill = &quot;Season&quot;, title=&quot;(a)&quot;) 3.3.4 Prepare data for speed ~ woodland plot # prepare data ele.speed.wood = as_data_frame(data) %&gt;% mutate(v.pred = predict(mod.speed, newdata = ., scale = &quot;response&quot;, allow.new.levels = T)) %&gt;% dplyr::select(woody.density, v, v.pred, season) %&gt;% mutate(v2 = v*2/1e3, v.pred2 = v.pred*2/1e3) %&gt;% dplyr::select(-v, -v.pred) %&gt;% tidyr::gather(var, value, -woody.density, -season) %&gt;% group_by(season, wood = plyr::round_any(woody.density, 5),var) %&gt;% summarise_at(vars(value), list(mean=mean, sd=sd, length=length)) %&gt;% mutate(ci = 1.96*sd/sqrt(length)) 3.3.5 Prepare Figure 4 (B): Speed and woody cover #review figs: speed vs slope, speed vs woody density fig_speed_wood = ggplot()+ geom_smooth(data = ele.speed.wood %&gt;% filter(var == &quot;v.pred2&quot;), aes(x = wood, y = mean, col = season, fill = season, lty = season), alpha = 0.2, size = 0.3)+ geom_pointrange(data = ele.speed.wood %&gt;% filter(var == &quot;v2&quot;), aes(x = wood, ymin = mean-ci, ymax = mean+ci, y = mean, col = season, shape = season), fill = &quot;white&quot;, position = position_dodge(width = 0.3), size = 0.4, stroke = 0.7)+ geom_rangeframe(data = data_frame(x=c(0,80),y=c(0.15,0.6)), aes(x,y))+ #facet_wrap(~var_name, scales = &quot;free_x&quot;)+ scale_color_brewer(palette = &quot;Set1&quot;)+ scale_fill_brewer(palette = &quot;Set1&quot;)+ scale_linetype_manual(values=c(2,1))+ scale_shape_manual(values= c(21,24))+ theme_few()+ theme(panel.border = element_blank(), legend.position = &quot;none&quot;)+ labs(x = &quot;Woody cover (%)&quot;, y = &quot;Speed (km/h)&quot;, title = &quot;(b)&quot;)+ scale_x_continuous(breaks = seq(0, 80, 20))+ scale_y_continuous(breaks = c(.15,.3,.45,.6), limits = c(NA, .6))+ coord_cartesian(ylim=c(.15,.6)) 3.4 Figure 4: Speed and temperature and woody cover half = 85/25.4; full = 180/25.4 # export fig for temp measures library(gridExtra) figure_04_speed = grid.arrange(fig_speed_temp, fig_speed_wood, nrow = 1) ggsave(figure_04_speed, filename = &quot;figs/figure_04_speed.pdf&quot;, height = half, width = full) library(magick) fig04 = magick::image_read_pdf(&quot;figs/figure_04_speed.pdf&quot;) fig04 (#fig:show_figure_04)Speed of elephant movement in relation to (a) collar temperature (at 2 ◦ C intervals) and (b) % woody cover (at 5 unit intervals) in the dry (red circles) and wet season (blue triangles). GAMM fit (lines) and 95% confidence intervals (vertical line ranges and shaded areas) are shown for each season separately. "],
["elephant-movement-between-water.html", "Section 4 Elephant movement between water 4.1 Concept: Movement between water 4.2 Load libraries 4.3 Load elephant data 4.4 Get time between water visits 4.5 Classify arrival and departure from water 4.6 Identify segments between water 4.7 Distance along segments 4.8 Segment metrics 4.9 Figure 5: Distance and displacement 4.10 Segment dynamics 4.11 Figure 6: Segment dynamics", " Section 4 Elephant movement between water Here, we look at elephants movement between water sources, and the speed, collar temperature, and distance to water along these segments. 4.1 Concept: Movement between water library(magick) fig02 = magick::image_read_pdf(&quot;figs/fig02_schematic.pdf&quot;) fig02 Schematic of elephant track segments between water points. The positions of elephants (black squares, denoted by pt x ) from GPS transmitters on collars within 200 m (green area) of a water source (river: blue rectangle, waterhole: blue circle) were identified as visits to water. For each individual elephant i, we identified track segments j (solid lines, denoted seg ij ) as the path joining all positions chronologically between successive departures from and arrivals at water points. Each segment began as the elephant departed the 200 m zone around water (green rhombi, pt 0 ), and ended at the position where the elephant arrived within a 200 m zone around water (orange circle). Positions at which elephants were continuously within 200 m of a water source (black square, pt w ) are joined by a dashed line, and were not included in the characterization of segments away from water. We calculated the time-difference between each segment’s start and end points as the segment time (t seg ), and identified the segment’s midpoint (purple triangle, pt 50 ) as the elephant position when half the segment time had elapsed (t seg /2). We computed the distance traveled between successive positions (pt x → pt x+1 ) in a segment as the steplength (v), and the sum of all v in a segment as the distance traveled along the segment (segment distance, d ij ). We calculated the linear distance (segment displacement, D) between each segment’s start and end points. Finally, we obtained the linear distance from each elephant position to the nearest water source (dw), the relative change in distance to water at each position (∆dw = dw 2 -dw 1 ), and the collar temperature at each position (T x ). 4.2 Load libraries # load libraries library(dplyr) library(purrr) library(lubridate) library(readr) library(readxl) library(glue) library(stringr) # spatial library(sf) # plotting library(ggplot2) library(ggthemes) # custom funcs ci = function(x) 1.96*sd(x, na.rm = T)/sqrt(length(x)) # frontiers figure sizes in inches full = 180/25.4; half = 85/25.4 4.3 Load elephant data Here we load elephant data and add a column identifying points which are within 200m of a water source. 200m is approximately the mean movement distance between two elephant positions. # load elephant data and find points within 200m of water data = read_csv(&quot;data/elephant_data.csv&quot;) data = data %&gt;% select(id, season, xutm, yutm, time, v, hour, mindw, temp, long, lat, angle) %&gt;% mutate(timenum = as.numeric(time)) %&gt;% group_by(id) %&gt;% mutate(waterdiff = c(NA, diff(mindw)), watervisits = as.numeric(mindw &lt;= 200)) What proportion of elphant locations are near water? # get proportions data_at_water = count(data, id, water = mindw &lt;= 200) %&gt;% group_by(id) %&gt;% mutate(prop_water = n/sum(n)) %&gt;% filter(water == TRUE) # write proportions write_csv(data_at_water, &quot;data/data_prop_at_water.csv&quot;) knitr::kable(read_csv(&quot;data/data_prop_at_water.csv&quot;) %&gt;% select(id, prop_water) %&gt;% mutate(prop_water = scales::percent(round(prop_water, 4)))) id prop_water AM105 20.56% AM107 28.43% AM108 19.14% AM110 22.81% AM239 19.31% AM253 29.88% AM254 18.27% AM255 22.91% AM306 26.62% AM307 21.01% AM308 15.14% AM91 24.86% AM93 20.68% AM99 21.70% 4.4 Get time between water visits How much time has passed between consecutive visits to water? # select watervisits and find the time since the previous one # remove points with NAs data_water = data %&gt;% filter(watervisits == 1) %&gt;% group_by(id) %&gt;% arrange(time) %&gt;% mutate(wvint = c(NA, diff(timenum))/3600) %&gt;% na.omit() 4.5 Classify arrival and departure from water Here we identify where the elphant arrives at water (or within 200m, rather), leaves from water, and is at water. # split by id, arrange by time, identify a change from water visit to non-watervisit points, # where there&#39;s a positive change, ie, status shifts from non-watervisit to watervisit, classify as arrival, # where a negative change, classify as departure, # where no change but point is within 200m of water, classify as at water, # all others where no change classify as segment points data = data %&gt;% left_join(data_water) %&gt;% split(data$id) %&gt;% map(function(df){ df %&gt;% arrange(timenum) %&gt;% mutate(ss = c(NA, diff(watervisits))) %&gt;% filter(!is.na(ss)) %&gt;% mutate(behav = case_when(ss == 1 ~ &quot;arrival&quot;, ss == -1 ~ &quot;departure&quot;, ss == 0 &amp; watervisits == 1 ~ &quot;at water&quot;, ss == 0 ~ &quot;segment&quot;, T~ as.character(NA))) }) # bind rows data &lt;- bind_rows(data) 4.5.1 Temperature at arrival # asked for in review, I believe # load lme4 library(lme4) # run model of temperature at arrival against the hour of arrival and season model_arrival_temp = lmer(temp ~ hour + season + (1|id), data = filter(data, behav == &quot;arrival&quot;)) # run model summary if(!dir.exists(&quot;data/model_output&quot;)){ dir.create(&quot;data/model_output&quot;) } # write model summary R.utils::captureOutput(summary(model_arrival_temp), file = &quot;data/model_output/model_arrival_temp.txt&quot;, append = TRUE) Print the model summary. cat(readLines(&quot;data/model_output/model_arrival_temp.txt&quot;), sep = &quot;\\n&quot;) Linear mixed model fit by REML [&#39;lmerMod&#39;] Formula: temp ~ hour + season + (1 | id) Data: filter(data, behav == &quot;arrival&quot;) REML criterion at convergence: 76221.9 Scaled residuals: Min 1Q Median 3Q Max -2.89970 -0.76294 -0.07497 0.85644 2.63490 Random effects: Groups Name Variance Std.Dev. id (Intercept) 0.7959 0.8922 Residual 40.1818 6.3389 Number of obs: 11663, groups: id, 14 Fixed effects: Estimate Std. Error t value (Intercept) 26.963889 0.277320 97.230 hour 0.124692 0.009198 13.557 seasonwet 0.103551 0.121320 0.854 Correlation of Fixed Effects: (Intr) hour hour -0.383 seasonwet -0.259 0.008 How long does each elephant usually remain near water? # subset points where elephants are at water or arriving data_water_duration &lt;- data %&gt;% split(&quot;id&quot;) %&gt;% map(function(df){ df %&gt;% arrange(timenum) %&gt;% filter(behav %in% c(&quot;at water&quot;,&quot;arrival&quot;)) %&gt;% mutate(watertime = cumsum(behav == &quot;arrival&quot;)) %&gt;% filter(behav == &quot;at water&quot;) %&gt;% group_by(id, watertime) %&gt;% summarise(duration_at_water = as.numeric(diff(range(time), units = &quot;hours&quot;))) }) %&gt;% bind_rows() %&gt;% ungroup() %&gt;% group_by(id) %&gt;% summarise_at(vars(duration_at_water), list(mean=mean, max=max, min=min, ci95=ci)) # write to file write_csv(data_water_duration, path = &quot;data/data_water_duration.csv&quot;) knitr::kable(read_csv(&quot;data/data_water_duration.csv&quot;)) id mean max min ci95 AM105 6.519551 59 0 0.8266358 AM107 6.955215 59 0 0.9149827 AM108 6.988697 59 0 0.9245382 AM110 6.700152 59 0 0.6767916 AM239 6.398075 59 0 0.7073521 AM253 7.176663 31 0 0.7363275 AM254 7.423451 59 0 0.8019367 AM255 7.464367 58 0 0.8823636 AM306 6.798591 59 0 1.0460625 AM307 7.339652 59 0 0.8722728 AM308 6.901941 59 0 1.1070726 AM91 7.735387 59 0 0.7235348 AM93 5.969936 31 0 0.7193454 AM99 7.124211 31 0 0.6603945 4.6 Identify segments between water 4.6.1 Count depatures and assign segment id # arrange by time, remove at water points, # assign segment id (loop) as cumulative sum of departures. # segments now begin at departures and end at arrival data = data %&gt;% split(&quot;id&quot;) %&gt;% map(function(x){ x %&gt;% arrange(timenum) %&gt;% filter(behav != &quot;at water&quot;) %&gt;% mutate(loop = cumsum(behav == &quot;departure&quot;)) }) %&gt;% bind_rows() 4.6.2 Summarise segments between water For each elephant and each segment, find 1. the segemnt duration in hours 2. the segment time in hours 3. the segment proportion in time. # run calculations on each elephant as list element data = data %&gt;% group_by(id, loop) %&gt;% mutate(loopdur = (last(timenum) - first(timenum))/3600, looptime = (timenum - first(timenum))/3600, loopprop = looptime/loopdur) } 4.6.3 Segments used and unused # review question, what&#39;s different between used and unused segments ele.used.segments = data %&gt;% filter(loopdur &lt; 120) %&gt;% group_by(id, loop) %&gt;% mutate(nfixes = length(xutm)) %&gt;% filter(nfixes &gt; 25) %&gt;% select(-nfixes) ele.unused.segments = data %&gt;% filter(loopdur &lt; 120) %&gt;% anti_join(ele.used.segments) # plot differences ele.unused.segments = ele.unused.segments %&gt;% mutate(type = &quot;unused&quot;) ele.used.segments = ele.used.segments %&gt;% mutate(type = &quot;used&quot;) # prep data ele.segment.data = bind_rows(ele.unused.segments, ele.used.segments) # show the loop duration differences between used and unused segments fig_used_segments = ggplot(ele.segment.data)+ geom_boxplot(aes(x = type, y = loopdur, col=type))+ theme_few()+ theme(legend.position = &quot;none&quot;)+ ylim(0,120)+ labs(x = NULL, y = &quot;segment duration (hrs)&quot;) # save figure ggsave(fig_used_segments, filename = &quot;figs/fig_used_segments.png&quot;) knitr::include_graphics(&quot;figs/fig_used_segments.png&quot;) (#fig:show_fig_used)Loop duration differences between segments used in this paper and those unused. 4.6.4 Collar temperature at water # get the temperature of eles at water, temp by hour fig_temp_at_water_hour = ggplot()+ geom_tufteboxplot(data = data_water, aes(x = as.factor(hour), y = temp, group = interaction(season, hour), col = season), median.type = &quot;line&quot;, whisker.type = &quot;point&quot;)+ scale_colour_brewer(palette = &quot;Set1&quot;)+ scale_x_discrete(breaks = c(0, 6, 12, 18, 22))+ scale_y_continuous(breaks = seq(10, 45, 5))+ theme_few()+ theme(legend.position = &quot;top&quot;)+ coord_cartesian(xlim=c(0,23), y = c(10,45), expand = T)+ geom_rangeframe(data=data_frame(x = c(1,23), y=c(10,45)), aes(x,y))+ labs(x = &quot;Hour of day&quot;, y = &quot;Collar temperature (°C)&quot;) # save figure ggsave(filename = &quot;figs/fig_temp_at_water.png&quot;, fig_temp_at_water_hour) ## Saving 7 x 5 in image Show the boxplot of collar temperature at water. knitr::include_graphics(&quot;figs/fig_temp_at_water.png&quot;) 4.6.5 Distribution of loop durations What is the distribution of durations of the used segments? # what is the 90th percentile of loop durations # around 120 hours quantile(data$loopdur, na.rm = T, 0.90) # diagnostic plot of loop durations fig_segment_distr = ggplot(data)+ stat_density(aes(x = loopdur, y = ..count.., col = season),geom = &quot;line&quot;, position = &quot;identity&quot;)+ scale_color_brewer(palette = &quot;Set1&quot;)+ scale_y_continuous()+ theme_few()+ theme(legend.position = &quot;top&quot;)+ labs(x = &quot;segment duration (hrs)&quot;, y = &quot;segments&quot;)+ xlim(0,120) # save figure ggsave(fig_segment_distr, filename = &quot;figs/fig_segment_distr.png&quot;) knitr::include_graphics(&quot;figs/fig_segment_distr.png&quot;) 4.7 Distance along segments # add distance along segments data = data %&gt;% ungroup() %&gt;% group_by(id, loop) %&gt;% arrange(time) %&gt;% mutate(distance = c(NA, sqrt(((xutm[2:length(xutm)] - xutm[1:length(xutm)-1])^2) + ((yutm[2:length(yutm)] - yutm[1:length(yutm)-1])^2)))) 4.8 Segment metrics Calculate a number of metrics for each segment: the first and last x-y coords, the season, the time taken for the loop to be completed, the mean speed, the temperature at the halfway point, the mean temperature along the loop, the instantaneous change in temp at the halfway stage. 4.8.1 Calculate segment metrics # get segment statistics data_summary = data %&gt;% filter(loopdur &lt; 120) %&gt;% group_by(id, loop) %&gt;% arrange(time) %&gt;% mutate(nfixes = length(xutm)) %&gt;% filter(nfixes &gt; 25) %&gt;% summarise(points = length(xutm), x1 = first(xutm), y1 = first(yutm), x2 = last(xutm), y2 = last(yutm), x50 = long[min(which(plyr::round_any(loopprop, 0.05) == 0.5))], y50 = lat[min(which(plyr::round_any(loopprop, 0.05) == 0.5))], long_start = first(long), lat_start = first(lat), long_end = last(long), lat_end = last(lat), season = first(season), looptime = max(looptime, na.rm = T), v = mean(v, na.rm = T), t50 = temp[min(which(plyr::round_any(loopprop, 0.05) == 0.5))], temp_mean = mean(temp, na.rm=T), temp_start = first(temp), temp_end = last(temp), wvint = first(wvint), distance = sum(distance, na.rm=T), maxdw = max(mindw,na.rm = T), hour_start = first(hour), hour_50 = hour[min(which(plyr::round_any(loopprop, 0.05) == 0.5))], hour_end = last(hour), mdw_start = first(mindw), mdw_end = last(mindw), time50 = time[min(which(plyr::round_any(loopprop, 0.05) == 0.5))], time_start = first(time), time_end = last(time)) 4.8.2 Segment displacement # remove initial segment and all segments with less than 2 points. data_summary = data_summary %&gt;% filter(loop &gt; 0, points &gt; 2) # get displacement data_summary = data_summary %&gt;% mutate(displace = sqrt(((x2-x1)^2) + ((y2-y1)^2))) 4.8.3 Quantify elephant shuttling # count shuttling data_summary %&gt;% ungroup() %&gt;% count(displace &lt;= 500) # count shuttling data_summary %&gt;% ungroup() %&gt;% count(displace &lt;= 1000) 4.8.4 Figure: Distance distributions Plot a figure of distance distribution per season. # prepare figure fig_segment_dist_distr = ggplot()+ stat_density(data = data_summary, aes(x = distance/1e3, y = ..count../sum(..count..)*2883, lty = season, col = season), position = &quot;identity&quot;, lwd = 0.7, geom = &quot;line&quot;)+ geom_rangeframe(data = data_frame(x=c(0,25), y=c(0,20)), aes(x,y))+ scale_colour_brewer(palette = &quot;Set1&quot;)+ scale_linetype_manual(values = c(2,1))+ scale_x_continuous(breaks = seq(0,25,5))+ scale_y_continuous(breaks = c(0,10, 20))+ theme_few()+ theme(legend.position = &quot;top&quot;, panel.border = element_blank())+ coord_cartesian(xlim = c(0,25))+ labs(x = &quot;Segment distance (km)&quot;, y = &quot;# Segments&quot;) # save figure ggsave(fig_segment_dist_distr, filename = &quot;figs/fig_distance_distribution.png&quot;) knitr::include_graphics(&quot;figs/fig_distance_distribution.png&quot;) 4.8.5 Figure: Displacement distributions Plot a figure of displacement distribution per season. # prepare figure fig_disp_distr = ggplot(data_summary)+ stat_density(aes(x = displace/1e3, y = ..count../sum(..count..)*2832, lty = season, col = season), position = &quot;identity&quot;, geom = &quot;line&quot;, size = 0.7)+ geom_rangeframe(data = data_frame(x=c(0,10),y=c(0,45)), aes(x,y))+ scale_color_brewer(palette = &quot;Set1&quot;)+ scale_linetype_manual(values = c(2,1))+ scale_x_continuous(breaks=seq(0,10,5))+ scale_y_continuous(breaks=c(0,15,30, 45))+ coord_cartesian(xlim=c(0,10), expand = T)+ theme_few()+ theme(legend.position = &quot;top&quot;, panel.border = element_blank())+ labs(x = &quot;Segment displacement (km)&quot;, y = &quot;# Segments&quot;) # save figure ggsave(fig_disp_distr, filename=&quot;figs/fig_displacement_distribution.png&quot;) knitr::include_graphics(&quot;figs/fig_displacement_distribution.png&quot;) (#fig:show_displacement_distribution)Distribution of displacement along segments between seasons. 4.9 Figure 5: Distance and displacement 4.9.1 Prepare data # prepare data dist.disp &lt;- data_summary %&gt;% group_by(mdist = plyr::round_any(distance, 500), season) %&gt;% summarise(mdisp = mean(displace, na.rm = T), sd = sd(displace, na.rm = T), n = length(displace)) %&gt;% mutate(ci = qnorm(0.975)*sd/sqrt(n)) # prepare figure fig_distance_displacement = ggplot()+ geom_rangeframe(data = data_frame(x=c(0,10), y=c(0,5)), aes(x,y))+ geom_segment(aes(x = 0,xend = 10,y=0,yend=10), size = 0.3)+ geom_pointrange(data = dist.disp, aes(x = mdist/1e3, y = mdisp/1e3, group = season, ymin = (mdisp-ci)/1e3, ymax = (mdisp+ci)/1e3, shape = season, col = season), fill = &quot;white&quot;, position = position_dodge(width = 0.8), size = 0.2)+ scale_shape_manual(values = c(21,24))+ scale_linetype_manual(values = c(2,1))+ scale_colour_brewer(palette = &quot;Set1&quot;)+ scale_fill_brewer(palette = &quot;Set1&quot;)+ scale_x_continuous(breaks=seq(0,10,5))+ scale_y_continuous(breaks=c(0,2.5,5))+ labs(x = &quot;Segment distance (km)&quot;, y = &quot;Segment displacement (km)&quot;)+ theme_few()+ theme(panel.border = element_blank(), legend.position=&quot;none&quot;)+ coord_cartesian(xlim = c(0,10), ylim = c(0,5), expand = T) # save figure half = 85/25.4; full = 180/25.4 ggsave(fig_distance_displacement, filename = &quot;figs/figure_05_distance_displacement.pdf&quot;, device = pdf(), height = half, width= half) library(magick) fig05 = magick::image_read_pdf(&quot;figs/figure_05_distance_displacement.pdf&quot;) fig05 (#fig:show_fig05)Segment displacement (km) between successive visits to water was positively correlated with the distance traveled along the segment (km). Vertical line ranges show 95% confidence intervals around mean values for the dry season (red circles) and wet season (blue triangles), respectively. The solid black line denotes values where displacement = distance. 4.10 Segment dynamics Here we look at data from segments with a duration of 30 or so hours. 4.10.1 Prepare data # now get only the loop and id data associated with these loops from ele6, which is all points segment_data = data_summary %&gt;% select(id, loop) %&gt;% left_join(data) %&gt;% mutate(v = v/1e3, mindw = mindw/1e3) %&gt;% select(id, loop, loopprop, mindw, waterdiff, temp, v, season, hour) 4.10.2 Statistics on segment data # use quadratic terms and run lmm directly library(lme4) loop.terms.stats = segment_data %&gt;% select(id, mindw, temp,v, season, loopprop) %&gt;% tidyr::gather(var, value, -id, -season, -loopprop) %&gt;% split(&quot;var&quot;) %&gt;% map(function(df){ lmer(value ~ I(loopprop^2) + season + (1|id), data = df) }) %&gt;% map(function(df){ list(summary(df), car::Anova(df)) }) # flatten and write to fle if required 4.11 Figure 6: Segment dynamics 4.11.1 Prepare data # get hourly speed segment_data = mutate(segment_data, v2 = v*2) # prepare data for figure data_fig = segment_data %&gt;% ungroup() %&gt;% select(loopprop, season, mindw, temp, v2) %&gt;% tidyr::gather(variable, value, -loopprop, -season) %&gt;% tidyr::drop_na() %&gt;% group_by(stage = plyr::round_any(loopprop, 0.1), season, variable) %&gt;% summarise_at(vars(value), list(mean=mean, sd=sd, length=length)) %&gt;% mutate(ci = 1.96*sd/sqrt(length), variable = as.factor(case_when( variable==&quot;mindw&quot;~&quot;Distance to water (km)&quot;, variable == &quot;temp&quot;~ &quot;Collar temperature (°C)&quot;, variable == &quot;v2&quot;~&quot;Speed (km/h)&quot;))) Review: How does speed along a segment compare with speed at the beginning? # get the speed relative to the first relative_speed = data_fig %&gt;% filter(variable == &quot;Speed (km/h)&quot;) %&gt;% group_by(season) %&gt;% mutate(relative_speed = mean/first(mean)) # write to file if needed 4.11.2 Prepare Figure 6 t = c(&quot;c&quot;,&quot;a&quot;,&quot;b&quot;) fig6list = list() # make a list of figures for (i in 1:3){ b &lt;- data_fig %&gt;% filter(variable == levels(variable)[i]) breaks &lt;- c(pretty(c(b$mean))) fig6list[[i]] = ggplot(b)+ geom_point(aes(x = stage, y = mean, col =season, group = interaction(variable, season), shape = season))+ geom_ribbon(aes(x = stage, ymin = mean-ci, ymax = mean+ci, fill = season), size = 0.3, alpha = 0.2)+ geom_rangeframe(data = data_frame(x=c(0,1), y = c(min(breaks), max(breaks))), aes(x,y))+ scale_shape_manual(values = c(21,24))+ scale_colour_brewer(palette = &quot;Set1&quot;)+ scale_fill_brewer(palette = &quot;Set1&quot;)+ scale_y_continuous(breaks = breaks)+ scale_x_continuous(breaks = c(0,0.5,1), labels = c(&quot;Start&quot;, &quot;Midpoint&quot;, &quot;End&quot;))+ theme_few()+ theme(legend.position = &quot;none&quot;, panel.border = element_blank())+ labs(x = NULL, y = levels(data_fig$variable)[i], title = paste(&quot;(&quot;,t[i],&quot;)&quot;, sep = &quot;&quot;)) } library(gridExtra) fig06 = grid.arrange(fig6list[[2]],fig6list[[3]],fig6list[[1]], ncol = 3) # save figure half = 85/25.4; full = 180/25.4 ggsave(fig06, filename = &quot;figs/figure_06_segment_dynamics.pdf&quot;, device = pdf(), height = half, width = full) library(magick) fig06 = magick::image_read_pdf(&quot;figs/figure_06_segment_dynamics.pdf&quot;) fig06 (#fig:show_figure_06)Elephant movement variables along segments between water points at 10% intervals of the segment stage (measured in time): (a) distance to the nearest water source (km), (b) speed (km/h), and (c) collar temperature (°C). Points are separated by season (dry = red circles, wet = blue triangles), and connected by lines. Ninety-five percent confidence intervals around each point are shown (note: CI may be too small to be visible for some points). "],
["preliminary-data-preparation.html", "Section 5 Preliminary data preparation 5.1 Load libraries 5.2 Load data 5.3 Preliminary checks 5.4 Fix problematic coordinates 5.5 Data distribution in time 5.6 Elephants near the weather station", " Section 5 Preliminary data preparation This section prepares the raw data to be used in the main methods. 5.1 Load libraries # load libraries library(dplyr) library(purrr) library(lubridate) library(readr) library(glue) library(stringr) # spatial library(sf) # plotting library(ggplot2) library(ggthemes) library(viridis) 5.2 Load data # load the preliminary data ele.dry = read_csv(&quot;data/ele_data/ele.dry.csv&quot;) ele.wet = read_csv(&quot;data/ele_data/ele.wet.csv&quot;) # combine to form a single dataset with seasons assigned ele.dry$season = &quot;dry&quot; ele.wet$season = &quot;wet&quot; #&#39;rbind the data ele = bind_rows(ele.dry, ele.wet) # susbet columns and rename ele = ele %&gt;% select(id = ID, ref = REF, long = LONGITUDE, lat = LATITUDE, temp = TEMP, season, xutm = XUTM, yutm = YUTM, time = Date_time, landscape = landsca, land.val = VALUE, density = DENSITY, woody.density = `woody density`, veg.class = VEG_CLASS, gertcode = Gertcode, v = STEPLENGTH, angle = TURNANGLE, heading = BEARING, distw = dist_water, distr = Dist_river) #&#39;change time to posixct via char ele$time = as.POSIXct(as.character(ele$time), tz = &quot;SAST&quot;, format = &quot;%d-%m-%Y %H:%M&quot;) # add hour and change column types ele = ele %&gt;% mutate(hour = hour(time), season = as.factor(season), gertcode = as.factor(gertcode)) 5.3 Preliminary checks We suspect that rows are not ordered in time. Check for this and correct it. Save the resulting data as data/ele_total.csv. # check for the minimum time lag between points. this must be greater than 0 # negtive time lags indicate positions are not ordered by time ele %&gt;% split(ele$id) %&gt;% map_chr(function(l){ min(as.numeric(diff(l$time))) &gt; 0 }) # check for weird coordinates # what are the bounding boxes (xmin, xmax, ymin, ymax) of each ele ele %&gt;% group_by(id) %&gt;% summarise_at(vars(long, lat), list(min=min, max=max)) # now check for ridiculous trajectories if(!dir.exists(&quot;figs/tracks&quot;)){ dir.create(&quot;figs/tracks&quot;) } # get kruger kruger = st_read(&quot;data/kruger_clip/&quot;) %&gt;% `st_crs&lt;-`(4326) kruger_utm = kruger %&gt;% st_transform(32736) ele %&gt;% split(ele$id) %&gt;% map(function(a){ a = arrange(a, time) fig_a_utm = ggplot(kruger_utm)+ geom_sf(fill = NA)+ geom_path(data = a, aes(xutm, yutm), lwd = 0.1)+ theme_few()+ labs(x=NULL, y=NULL, title = unique(a$id), subtitle = &quot;UTM data&quot;) fig_a = ggplot(kruger)+ geom_sf(fill = NA)+ geom_path(data = a, aes(long, lat), lwd = 0.1)+ theme_few()+ labs(x=NULL, y=NULL, title = unique(a$id), subtitle = &quot;longlat data&quot;) fig = gridExtra::grid.arrange(fig_a, fig_a_utm, ncol = 2) ggsave(fig, filename = glue(&#39;figs/tracks/track_{unique(a$id)}.png&#39;)) }) Some elephants (239, 254, 255, 307, 308) have errored UTM coordinates which need to be ffixed. There are two issues: first, poor merging of the UTM converted coordinates with the parent data.frame at some stage prior to being processed for this paper (239 – 255). Second, two elephants, 307 and 308, seem to have had their UTM coordinates cropped to the limits of the Kruger shapefile, while the long-lat coordinates are preserved. knitr::include_graphics(c(&quot;figs/tracks/track_AM254.png&quot;, &quot;figs/tracks/track_AM307.png&quot;)) (#fig:show_ele_problems1)Problematic conversion of elephant tracking data coordinates from long-lat to UTM. (#fig:show_ele_problems2)Problematic conversion of elephant tracking data coordinates from long-lat to UTM. 5.4 Fix problematic coordinates # fix all elephant utm coordinates by doing a fresh transform ele = ele %&gt;% split(ele$id) %&gt;% map(function(l){ geo = select(l, time, long, lat) %&gt;% arrange(time) l = select(l, -xutm, -yutm) utm = st_as_sf(geo, coords = c(&quot;long&quot;, &quot;lat&quot;)) %&gt;% `st_crs&lt;-`(4326) %&gt;% st_transform(32736) %&gt;% st_coordinates() %&gt;% as_tibble() %&gt;% rename(xutm = &quot;X&quot;, yutm = &#39;Y&#39;) l = cbind(l, utm) }) # run time checks ele %&gt;% split(ele$id) %&gt;% map_chr(function(l){ min(as.numeric(diff(l$time))) &gt; 0 }) # examine tracks on a map prob_eles = filter(ele, id %in% c(&quot;AM239&quot;, &quot;Am254&quot;, &quot;AM255&quot;, &quot;AM307&quot;, &quot;AM308&quot;)) fig_fixed_eles = ggplot(kruger_utm)+ geom_sf(fill = NA)+ geom_path(data = prob_eles, aes(x=xutm, y=yutm, group = id, col = id), lwd = 0.1)+ theme_few()+ labs(x=NULL, y=NULL) # save figure ggsave(fig_fixed_eles, filename = glue(&#39;figs/tracks/track_fixed_eles.png&#39;)) knitr::include_graphics(&quot;figs/tracks/track_fixed_eles.png&quot;) (#fig:show_ele_fixed)Problem elephant coordinates are now fixed. 5.4.1 Save fixed coordinates write_csv(ele, path = &quot;data/elephant_data.csv&quot;) 5.5 Data distribution in time 5.5.1 Seasonal summary # how many positions per elephant per year and season data_season_summary = ele %&gt;% group_by(year_season = paste(year(time), season, sep = &quot; &quot;)) %&gt;% count(id) # make figure fig_season_summary = ggplot(data_season_summary)+ geom_tile(aes(x = id, y = year_season, fill = n))+ scale_fill_viridis()+ theme_few()+ labs(x = &quot;elephant id&quot;,y = &quot;year &amp; season&quot;, fill = &quot;positions&quot;)+ coord_flip() # save figure ggsave(fig_season_summary, filename = &quot;figs/fig_season_summary.png&quot;, width = 8, height = 6) # import and show knitr::include_graphics(&quot;figs/fig_season_summary.png&quot;) 5.5.2 Monthly summary # positions per elephant per month and year data_month_summary = group_by(ele, year_month = glue(&#39;{year(time)} {str_pad(month(time), width = 2, pad = &quot;0&quot;)}&#39;)) %&gt;% count(id) # make figure fig_month_summary = ggplot(data_month_summary)+ geom_tile(aes(x = id, y = year_month, fill = n))+ scale_fill_viridis()+ theme_few()+ theme(axis.text.x = element_text(size = 4))+ labs(fill = &quot;positions&quot;, x = &quot;Individual&quot;, y = &quot;Year month&quot;)+ coord_flip() # save figure ggsave(fig_month_summary, filename = &quot;figs/fig_month_summary.png&quot;, width = 12, height = 6) # import and show knitr::include_graphics(&quot;figs/fig_month_summary.png&quot;) 5.6 Elephants near the weather station Which elephants are within 10 km of the weather station at Skukuza, and when? 5.6.1 Load Skukuza The weather station at Skukuza (24.9 S, 31.5 E) is our source for ambient temperature data. # load skukuza and make sf skukuza = read_csv(&quot;data/skukuza.csv&quot;) skukuza = st_as_sf(skukuza, coords = c(&quot;long&quot;, &quot;lat&quot;)) %&gt;% `st_crs&lt;-`(4326) %&gt;% st_transform(32736) # get buffer around skukuza skz_buf = st_buffer(skukuza, dist = 10000) 5.6.2 Select elephants within 10 km # make eles sf and crop by buffer ele_sf = st_as_sf(ele[, c(&quot;long&quot;, &quot;lat&quot;)], coords = c(&quot;long&quot;, &quot;lat&quot;)) %&gt;% `st_crs&lt;-`(4326) %&gt;% st_transform(32736) ele_keep = st_contains(skz_buf, ele_sf) ele_keep = unlist(ele_keep) # eles to keep ele_tower = ele[ele_keep,] 5.6.3 Get distribution over time #&#39;which eles are here and over which months? data_tower_summary = group_by(ele_tower, year_month = glue(&#39;{year(time)} {str_pad(month(time), width = 2, pad = &quot;0&quot;)}&#39;)) %&gt;% count(id) # make figure fig_tower_summary = ggplot(data_tower_summary)+ geom_tile(aes(x = id, y = year_month, fill = n))+ scale_fill_viridis(option=&quot;C&quot;)+ theme_few()+ labs(fill = &quot;positions&quot;, x = &quot;elephant&quot;, y = &quot;year month&quot;)+ coord_flip() # save figure ggsave(fig_tower_summary, filename = &quot;figs/fig_tower_summary.png&quot;, width = 10, height = 4) # import and show knitr::include_graphics(&quot;figs/fig_tower_summary.png&quot;) "],
["getting-spatial-data.html", "Section 6 Getting spatial data 6.1 Load libraries 6.2 Getting temperature data 6.3 Getting elevation data 6.4 Reproject data to UTM 36S", " Section 6 Getting spatial data 6.1 Load libraries # load libraries library(purrr) library(ggplot2) This section looks at using Google Earth Engine (Gorelick et al. 2017) to retrieve remote sensing data and process it for use. This code is in Javascript. The cropped raster can be saved to your Google Drive. Retrieval of the raster from Drive is not covered. The data are much too large to be rendered here, and their inspection is also not covered. 6.2 Getting temperature data Code to get 30m thermal data from LANDSAT-5 (Schmidt et al. 2013). // get extent and landsat 5 data var geometry = /* color: #ff3d3d */ee.Geometry.Polygon( [[[77.26686452041235, 13.344492655458648], [77.26803063514615, 12.69020162411501], [78.31220864869454, 12.698000169170149], [78.31998125667042, 13.342950249131635]]]), table = ee.FeatureCollection(&quot;users/pratik_unterwegs/ele_ext&quot;), table2 = ee.FeatureCollection(&quot;users/pratik_unterwegs/kruger_clip&quot;), l5 = ee.ImageCollection(&quot;LANDSAT/LT05/C01/T1_SR&quot;); //define func var crop = function(x){ var image = x. clip(table). divide(10). subtract(273); return image; } // filter landsat 5 data for time, cloud cover, and thermal band var filtered = l5.filterDate(&#39;2007-08-01&#39;, &#39;2009-08-30&#39;). filterMetadata(&#39;CLOUD_COVER&#39;, &#39;less_than&#39;, 10). select(&#39;B6&#39;). map(crop). mean(); var rgb_viz = {min: 20, max: 35, bands:[&#39;B6&#39;], palette: [&quot;#0D0887FF&quot;, &quot;#4C02A1FF&quot;, &quot;#7E03A8FF&quot;, &quot;#A92395FF&quot;, &quot;#CC4678FF&quot;, &quot;#E56B5DFF&quot;,&quot;#F89441FF&quot;, &quot;#FDC328FF&quot;, &quot;#F0F921FF&quot;] }; Map.addLayer(filtered, rgb_viz, &#39;kruger_temp&#39;); // export to google drive Export.image.toDrive({ image: filtered, description: &#39;kruger_temperature&#39;, scale: 30, region: table.geometry()}); 6.3 Getting elevation data Code to get 30m elevation data from SRTM (Farr et al. 2007) using the Google Earth Engine Javascript API. This data was acquired and later not used. //load SRTM data and elephant extent var image = ee.Image(&quot;USGS/SRTMGL1_003&quot;), table = ee.FeatureCollection(&quot;users/pratik_unterwegs/ele_ext&quot;), ext = ee.FeatureCollection(&quot;users/pratik_unterwegs/ele_ext&quot;), geometry = ee.Geometry.MultiPoint(); //filter 30m DEM for the polygon var srtm_clip = image.clip(ext.geometry()); Map.addLayer(table); //get slope var srtm_slope = ee.Terrain.slope(srtm_clip); //check elevation map Map.addLayer(srtm_clip, {min: 0, max :500, palette: [&quot;#00A600FF&quot;, &quot;#2DB600FF&quot;, &quot;#63C600FF&quot;, &quot;#A0D600FF&quot;, &quot;#E6E600FF&quot;, &quot;#E8C32EFF&quot;, &quot;#EBB25EFF&quot;, &quot;#EDB48EFF&quot;, &quot;#F0C9C0FF&quot;, &quot;#F2F2F2FF&quot; ]}, &#39;elevation&#39;); // check slope map Map.addLayer(srtm_slope, {min: 0, max :10, palette: [&quot;#00A600FF&quot;, &quot;#2DB600FF&quot;, &quot;#63C600FF&quot;, &quot;#A0D600FF&quot;, &quot;#E6E600FF&quot;, &quot;#E8C32EFF&quot;, &quot;#EBB25EFF&quot;, &quot;#EDB48EFF&quot;, &quot;#F0C9C0FF&quot;, &quot;#F2F2F2FF&quot; ]}, &#39;slope&#39;); //export to file Export.image.toDrive({ image: srtm_clip, description: &#39;kruger_elevation&#39;, scale: 30, region: table.geometry() }); Export.image.toDrive({ image: srtm_slope, description: &#39;kruger_slope&#39;, scale: 30, region: table.geometry() }); 6.4 Reproject data to UTM 36S # use gdalwarp from gdalutils library(gdalUtils) library(stringr) library(glue) # list the files and warp them kruger_terrain = list.files(&quot;data&quot;, pattern = &quot;kruger_&quot;, full.names = TRUE) map(kruger_terrain, function(df){ name = str_split(df, &quot;.tif&quot;, simplify = TRUE)[,1] gdalwarp(srcfile = df, dstfile = as.character(glue(&#39;{name}_UTM.tif&#39;)), t_srs = &quot;+proj=utm +zone=36 +south +datum=WGS84 +units=m +no_defs&quot;, tr = c(30,30)) }) References "],
["getting-distance-to-water.html", "Section 7 Getting distance to water 7.1 Load libraries 7.2 Load water features 7.3 Load elephant data 7.4 Add distance to water by season 7.5 Write data to file", " Section 7 Getting distance to water Here we cover adding data related to landscape features: 1. Distance to the nearest water source 2. Temperature measured by LANDSAT 7.1 Load libraries # load libraries library(dplyr) library(purrr) library(lubridate) library(readr) library(glue) library(stringr) # spatial library(sf) # plotting library(ggplot2) library(ggthemes) library(viridis) 7.2 Load water features We load water features from an OpenStreetMap (OpenStreetMap contributors 2017) dump accessed in mid 2018. # load rivers, or linear water features rivers = st_read(&quot;data/river_crop/kruger_rivers_cropped.shp&quot;) # load waterholes or point features wh = st_read(&quot;data/waterholes/&quot;) # read the extent of elephant data ext = st_read(&quot;data/ele_ext&quot;) # filter waterholes by the extent wh = filter(wh, CURRENT==&quot;Open&quot;) %&gt;% st_crop(ext) %&gt;% st_union() 7.3 Load elephant data # load elephant data and make it sf on UTM coords data = read_csv(&quot;data/elephant_data.csv&quot;) data_sf = st_as_sf(data, coords = c(&quot;xutm&quot;, &quot;yutm&quot;)) %&gt;% `st_crs&lt;-`(32736) # get distance to waterholes and rivers distwh = as.numeric(st_distance(data_sf, wh)) river_season = list(distr_seasonal = rivers %&gt;% filter(is.na(seasonal)), distr = (rivers)) %&gt;% map(st_union) distr_seasonal = map(river_season, function(l){ return(as.numeric(st_distance(data_sf, l))) }) 7.4 Add distance to water by season # add distance to rivers data data = mutate(data, distr = distr_seasonal[[&quot;distr&quot;]], distr_s = distr_seasonal[[&quot;distr_seasonal&quot;]], distwh = distwh) # calculate mindw, the minimum distance to water data = data %&gt;% mutate(mindw = case_when( season ==&quot;dry&quot;~ifelse(distr_s &lt; distwh, distr_s, distwh), season == &quot;wet&quot;~ifelse(distr &lt; distwh, distr, distwh), T~as.double(NA) )) 7.5 Write data to file write_csv(data, &quot;data/elephant_data.csv&quot;) "]
]
